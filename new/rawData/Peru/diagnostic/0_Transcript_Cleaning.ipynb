{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Snapshot Timestamp Tagging Notebook\n",
        "\n",
        "This Jupyter-notebook walks through the complete pipeline for **inserting snapshot markers** into observation-segment transcripts.  \n",
        "After execution you will have a new file, **`TIMESTAMPED_peru_cleaned_transcripts.csv`**, that contains the modified transcript text with inline tags identifying three key one-minute windows:\n",
        "\n",
        "| Snapshot | Minutes | Seconds | Tag |\n",
        "|----------|---------|---------|------|\n",
        "| 1        | 4 – 5   | 240 – 300 | `<SNAPSHOT 1> … </SNAPSHOT 1>` |\n",
        "| 2        | 9 – 10  | 540 – 600 | `<SNAPSHOT 2> … </SNAPSHOT 2>` |\n",
        "| 3        | 14 – 15 | 840 – 900 | `<SNAPSHOT 3> … </SNAPSHOT 3>` |\n",
        "\n",
        "Only the text inside these ranges is wrapped; everything else remains exactly as recorded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 — Setup\n",
        "\n",
        "We import core libraries and set paths to the source and destination CSV files.  \n",
        "Feel free to adjust `SOURCE_CSV` and `DEST_CSV` if your directory layout differs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# ----- Paths ------------------------------------------------------------\n",
        "SOURCE_CSV = Path(\"/Users/mkrasnow/Desktop/montesa/new/formattedData/peru_cleaned_transcripts.csv\")\n",
        "DEST_CSV   = SOURCE_CSV.parent / \"TIMESTAMPED_peru_cleaned_transcripts.csv\"\n",
        "\n",
        "assert SOURCE_CSV.exists(), f\"Source CSV not found: {SOURCE_CSV}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 — Snapshot-insertion utility\n",
        "\n",
        "Below is a single helper function, **`insert_snapshot_tags`**, that takes the raw JSON string from any transcript column and returns the text with snapshot tags inserted at the correct points.\n",
        "\n",
        "### Algorithm overview\n",
        "1. Parse the JSON into a dictionary (no external schema required).  \n",
        "2. Walk through the words chronologically.  \n",
        "3. Open a `<SNAPSHOT n>` tag once we **enter** its window (first word ≥ window start).  \n",
        "4. Close with a `</SNAPSHOT n>` tag on the first word whose `start` time **exceeds** the window end.  \n",
        "5. Emit the word’s text exactly as stored.  \n",
        "6. Join tokens with spaces and perform a light tidy-up for readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "SNAPSHOT_WINDOWS: List[Tuple[int, float, float]] = [\n",
        "    (1, 4 * 60, 5 * 60),   # 4:00 – 4:59.999 … up to 300 s\n",
        "    (2, 9 * 60, 10 * 60),  # 9:00 – 9:59.999 … up to 600 s\n",
        "    (3, 14 * 60, 15 * 60)  # 14:00 – 14:59.999 … up to 900 s\n",
        "]\n",
        "\n",
        "def insert_snapshot_tags(transcript_json: str) -> str:\n",
        "    \"\"\"Return transcript text with <SNAPSHOT n> markers inserted.\"\"\"\n",
        "    if not isinstance(transcript_json, str) or not transcript_json.strip():\n",
        "        return \"\"\n",
        "\n",
        "    try:\n",
        "        t_dict = json.loads(transcript_json)\n",
        "    except json.JSONDecodeError:\n",
        "        # If the JSON is malformed we leave the cell blank rather than crashing.\n",
        "        return \"\"\n",
        "\n",
        "    words = t_dict.get(\"words\", [])\n",
        "    if not words:\n",
        "        return t_dict.get(\"text\", \"\")\n",
        "\n",
        "    # Track whether we are *inside* a given snapshot window.\n",
        "    in_window = {num: False for num, _s, _e in SNAPSHOT_WINDOWS}\n",
        "    tagged_tokens: List[str] = []\n",
        "\n",
        "    for w in words:\n",
        "        start_time = float(w.get(\"start\", 0.0))\n",
        "        token_text = w.get(\"text\", \"\")\n",
        "\n",
        "        # Open or close snapshot tags as required before appending the token.\n",
        "        for num, win_start, win_end in SNAPSHOT_WINDOWS:\n",
        "            if (not in_window[num]) and start_time >= win_start and start_time < win_end:\n",
        "                tagged_tokens.append(f\"<SNAPSHOT {num}>\")\n",
        "                in_window[num] = True\n",
        "\n",
        "            if in_window[num] and start_time >= win_end:\n",
        "                tagged_tokens.append(f\"</SNAPSHOT {num}>\")\n",
        "                in_window[num] = False\n",
        "\n",
        "        tagged_tokens.append(token_text)\n",
        "\n",
        "    # Close any snapshot still open at the end of the transcript.\n",
        "    for num, _s, _e in SNAPSHOT_WINDOWS:\n",
        "        if in_window[num]:\n",
        "            tagged_tokens.append(f\"</SNAPSHOT {num}>\")\n",
        "            in_window[num] = False\n",
        "\n",
        "    # Join on spaces; then collapse any multiple-space sequences introduced during tagging.\n",
        "    final_text = \" \".join(tagged_tokens)\n",
        "    return \" \".join(final_text.split())  # simple whitespace normalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 — Load data and apply tagging\n",
        "\n",
        "The dataset contains two transcript-JSON columns and two human-readable text columns.  \n",
        "Our task is to **overwrite** the text columns with snapshots inserted, leaving everything else untouched."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Snapshot insertion complete for all rows.\n"
          ]
        }
      ],
      "source": [
        "# Read the cleaned transcripts CSV\n",
        "df = pd.read_csv(SOURCE_CSV)\n",
        "\n",
        "COLUMN_PAIRS = [\n",
        "    (\"First Audio Transcript_JSON\", \"First Audio Transcript Text\"),\n",
        "    (\"Last Audio Transcript_JSON\",  \"Last Audio Transcript Text\"),\n",
        "]\n",
        "\n",
        "for json_col, text_col in COLUMN_PAIRS:\n",
        "    if json_col not in df.columns or text_col not in df.columns:\n",
        "        raise KeyError(f\"Expected columns '{json_col}' and '{text_col}' not found in CSV header.\")\n",
        "\n",
        "    df[text_col] = df[json_col].apply(insert_snapshot_tags)\n",
        "\n",
        "print(\"Snapshot insertion complete for all rows.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 — Save result\n",
        "\n",
        "The final DataFrame is saved alongside the original with the mandated filename."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅  Saved timestamp-tagged transcripts to:  /Users/mkrasnow/Desktop/montesa/new/formattedData/TIMESTAMPED_peru_cleaned_transcripts.csv\n"
          ]
        }
      ],
      "source": [
        "df.to_csv(DEST_CSV, index=False)\n",
        "print(f\"✅  Saved timestamp-tagged transcripts to:  {DEST_CSV}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 — Run notebook end-to-end\n",
        "\n",
        "1. Execute every cell (⏯ **Run All**).  \n",
        "2. Confirm the console prints the success message.  \n",
        "3. Verify the new CSV in the same directory.  \n",
        "\n",
        "> **Tip** If your notebook kernel has no `pandas` installed, run `pip install pandas` in a fresh cell before the import section."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Harvard",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
