{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1027059e",
      "metadata": {},
      "source": [
        "# N/A Count vs Transcript Length - Analysis Notebook\n",
        "This notebook analyzes the relationship between AI evaluation missing values (N/A counts) and transcript word counts, identifies problematic clips, and offers a data-driven cleaning step based on knee/elbow threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "78be5549",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Imports and Setup ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "sns.set(style='whitegrid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bf409377",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kneed\n",
            "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /opt/anaconda3/envs/Harvard/lib/python3.12/site-packages (from kneed) (2.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/envs/Harvard/lib/python3.12/site-packages (from kneed) (1.14.1)\n",
            "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: kneed\n",
            "Successfully installed kneed-0.8.5\n"
          ]
        }
      ],
      "source": [
        "# Install knee detection library\n",
        "!pip install kneed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "78b2b85d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluations: (118, 41), Transcripts: (203, 73)\n"
          ]
        }
      ],
      "source": [
        "# --- Load Data ---\n",
        "# Adjust paths as needed\n",
        "eval_df = pd.read_csv('/Users/mkrasnow/Desktop/montesa/new/rawData/Peru/model_evaluation_data/BaseEvaluator_evaluations.csv', na_values=['N/A'])\n",
        "trans_df = pd.read_csv('/Users/mkrasnow/Desktop/montesa/new/formattedData/peru_cleaned_transcripts.csv')\n",
        "print(f'Evaluations: {eval_df.shape}, Transcripts: {trans_df.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5e0ff93b",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'School_Clip'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/opt/anaconda3/envs/Harvard/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'School_Clip'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Extract Group Identifier ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Extract the 6-7 digit School_Clip identifier for pairing\u001b[39;00m\n\u001b[1;32m      3\u001b[0m trans_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trans_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSchool_Clip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m6,7})\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m eval_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eval_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSchool_Clip\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m6,7})\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m/opt/anaconda3/envs/Harvard/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/opt/anaconda3/envs/Harvard/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'School_Clip'"
          ]
        }
      ],
      "source": [
        "# --- Extract Group Identifier ---\n",
        "# Extract the 6-7 digit School_Clip identifier for pairing\n",
        "trans_df['group_id'] = trans_df['School_Clip'].str.extract(r'^(\\d{6,7})')[0]\n",
        "eval_df['group_id'] = eval_df['School_Clip'].str.extract(r'^(\\d{6,7})')[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d219bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Merge Word Counts and Count N/A ---\n",
        "# Map transcript word count based on clip_number ('first' or 'last')\n",
        "def get_word_count(row):\n",
        "    grp = trans_df.loc[trans_df['group_id'] == row['group_id']]\n",
        "    if row['clip_number'] == 'first':\n",
        "        return int(grp['First Audio Transcript Word Count'].values[0])\n",
        "    else:\n",
        "        return int(grp['Last Audio Transcript Word Count'].values[0])\n",
        "\n",
        "eval_df['word_count'] = eval_df.apply(get_word_count, axis=1)\n",
        "# Count N/A per evaluation row\n",
        "eval_cols = [c for c in eval_df.columns if c not in ['group_id','School_Clip','clip_number','model_name']]\n",
        "eval_df['na_count'] = eval_df[eval_cols].isna().sum(axis=1)\n",
        "# Aggregate metrics per clip (group)\n",
        "group_metrics = eval_df.groupby('group_id').agg(\n",
        "    word_count=('word_count', 'sum'),\n",
        "    na_count=('na_count', 'sum')\n",
        ").reset_index()\n",
        "total_nas = group_metrics['na_count'].sum()\n",
        "print(f'Total N/A entries (group-level): {total_nas}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73b8e41",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Scatter Plot: Word Count vs. N/A Count (Group-level) ---\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(group_metrics['word_count'], group_metrics['na_count'], alpha=0.6)\n",
        "plt.xlabel('Total Transcript Word Count per Clip')\n",
        "plt.ylabel('Total N/A Count per Clip')\n",
        "plt.title('N/A Count vs. Transcript Length (Group-level)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a05bac3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Elbow Analysis: Trade-off Between Dropped Clips and N/A Removal ---\n",
        "# Prepare thresholds and metrics\n",
        "thresholds = sorted(group_metrics['word_count'].unique())\n",
        "rows_removed_pct, nas_removed_pct = [], []\n",
        "for t in thresholds:\n",
        "    to_drop = group_metrics[group_metrics['word_count'] < t]\n",
        "    rows_removed_pct.append(len(to_drop) / len(group_metrics))\n",
        "    nas_removed_pct.append(to_drop['na_count'].sum() / total_nas)\n",
        "# Plot trade-off curve\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(rows_removed_pct, nas_removed_pct, marker='o')\n",
        "plt.xlabel('Fraction of Clips Removed')\n",
        "plt.ylabel('Fraction of N/A Eliminated')\n",
        "plt.title('Elbow Curve: Data Removal vs. Missing Evaluation Reduction')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690100a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Knee Detection for Threshold Selection ---\n",
        "from kneed import KneeLocator\n",
        "# Identify knee point on the trade-off curve\n",
        "kneedle = KneeLocator(rows_removed_pct, nas_removed_pct, curve='convex', direction='increasing')\n",
        "knee_frac = kneedle.knee\n",
        "# Determine the corresponding word count threshold\n",
        "knee_index = rows_removed_pct.index(knee_frac)\n",
        "SELECTED_THRESHOLD = thresholds[knee_index]\n",
        "print(f'Knee detected at removing {knee_frac*100:.1f}% of clips, word count threshold = {SELECTED_THRESHOLD}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c079aca3",
      "metadata": {},
      "source": [
        "## ROC/AUC Approach for Threshold Validation\n",
        "We treat the presence of any missing evaluations as a binary target and evaluate total transcript length per clip as a classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a41f89",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- ROC Curve (Group-level) ---\n",
        "labels = (group_metrics['na_count'] > 0).astype(int)\n",
        "scores = -group_metrics['word_count']\n",
        "fpr, tpr, _ = roc_curve(labels, scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve: Missing Data vs. Transcript Length (Group-level)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5074da9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Final Cleaning of Transcripts based on Selected Threshold ---\n",
        "# Identify groups to keep\n",
        "keep_groups = group_metrics[group_metrics['word_count'] >= SELECTED_THRESHOLD]['group_id']\n",
        "final_transcripts = trans_df[trans_df['group_id'].isin(keep_groups)].copy()\n",
        "print(f\"Original transcript rows: {len(trans_df)}, Final transcript rows: {len(final_transcripts)}\")\n",
        "# Save the cleaned transcripts\n",
        "final_transcripts.to_csv('/Users/mkrasnow/Desktop/montesa/new/formattedData/FINAL_peru_cleaned_transcripts.csv', index=False)\n",
        "print('Saved FINAL_peru_cleaned_transcripts.csv')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Harvard",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
