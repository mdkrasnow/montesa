{"cells":[{"cell_type":"markdown","id":"373d0e44","metadata":{"id":"373d0e44"},"source":["# Audio Transcription ‚Äì Peru Audio Clips  \n","### **GPU-Enhanced, Progress-Aware, Multi-Threaded Pipeline (ElevenLabs Scribe)**\n","\n","This notebook transcribes Spanish MP3 audio clips to **text** **transcripts** using\n","the new **ElevenLabs Scribe v1** Speech-to-Text API, replacing the previous Groq Whisper flow.\n","\n","---\n","\n","**Key Enhancements (relative to the Groq version)**\n","\n","| Area | Upgrade |\n","|------|---------|\n","| STT engine | Switched to ElevenLabs Scribe v1 ‚Äì 99-language, word-timestamped, speaker-diarized output. |\n","| Diarization | Native `diarize` flag with `num_speakers` hint for up to 32 speakers. |\n","| Spanish mode | `language_code=\"es\"` consistently enforced. |\n","| Cost ledger | Updated to $0.40 h / $0.00667 min pricing. |\n","| API client | Uses the **official `elevenlabs` Python SDK**. |\n","| **Deduplication** | **NEW: Identifier-based deduplication to avoid transcribing same clips multiple times.** |\n"]},{"cell_type":"code","execution_count":1,"id":"6be7f463","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17129,"status":"ok","timestamp":1748965309239,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"6be7f463","outputId":"89c17d62-12f2-4229-e6a5-017c457446d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m682.9/682.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ Dependencies installed/verified\n"]}],"source":["# --- Install dependencies ---------------------------------------------------\n","import importlib.util, subprocess, sys, os\n","\n","# Ensure required packages are installed both in Colab and in a local Jupyter environment.\n","pkgs = [\n","    'elevenlabs',\n","    'python-dotenv',\n","    'requests',\n","    'pandas',\n","    'tqdm',\n","    'psutil',\n","    'soundfile',\n","    'librosa'\n","]\n","\n","IN_COLAB = importlib.util.find_spec('google.colab') is not None\n","\n","if IN_COLAB:\n","    # Colab: use shell magic for speed and readability\n","    from IPython import get_ipython\n","    get_ipython().system('pip -q install ' + ' '.join(pkgs))\n","else:\n","    # Local: run pip quietly via subprocess (only installs missing packages)\n","    subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', *pkgs], check=True)\n","\n","print('‚úÖ Dependencies installed/verified')\n"]},{"cell_type":"code","execution_count":2,"id":"2b9053d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1748965309304,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"2b9053d2","outputId":"9b602cf8-e16c-4fd9-ebd2-75a6e0951f67"},"outputs":[{"output_type":"stream","name":"stdout","text":["No NVIDIA GPU or nvidia-smi failed: [Errno 2] No such file or directory: 'nvidia-smi'\n","üíª Using CPU-only mode for local tasks\n"]}],"source":["# --- Environment & GPU detection -------------------------------------------\n","import importlib.util, subprocess, os, sys, json, time, hashlib, psutil\n","from pathlib import Path\n","from datetime import datetime\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","from threading import Lock, Semaphore, Event\n","import re\n","from collections import defaultdict\n","\n","IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n","CPU_COUNT = os.cpu_count() or 1\n","CHUNK_SIZE = 8192\n","\n","# GPU detection (unchanged helper)\n","def detect_gpu_and_configure():\n","    gpu = {'available': False, 'memory_gb': 0, 'acceleration_flag': '', 'max_concurrent': 1}\n","    try:\n","        out = subprocess.run(['nvidia-smi','--query-gpu=memory.total','--format=csv,noheader,nounits'],\n","                             capture_output=True, text=True, timeout=10)\n","        if out.returncode==0:\n","            mem_mb=int(out.stdout.strip())\n","            mem_gb=mem_mb/1024\n","            gpu.update({'available': True,\n","                        'memory_gb': mem_gb,\n","                        'acceleration_flag': '-hwaccel cuda',\n","                        'max_concurrent': 4 if mem_gb>=16 else 2 if mem_gb>=8 else 1})\n","            print(f\"üöÄ NVIDIA GPU: {mem_gb:.1f} GB - {gpu['max_concurrent']} concurrent heavy tasks\")\n","    except Exception as e:\n","        print(\"No NVIDIA GPU or nvidia-smi failed:\", e)\n","    if not gpu['available']:\n","        print(\"üíª Using CPU-only mode for local tasks\")\n","    return gpu\n","\n","GPU_INFO = detect_gpu_and_configure()\n","GPU_SEMAPHORE = Semaphore(GPU_INFO['max_concurrent']) if GPU_INFO['available'] else None\n","GPU_MONITOR_STOP = Event()\n","\n","def start_gpu_monitor(interval=60):\n","    if not GPU_INFO['available']: return None\n","    def _loop():\n","        while not GPU_MONITOR_STOP.is_set():\n","            try:\n","                out = subprocess.run(['nvidia-smi','--query-gpu=utilization.gpu,memory.used,memory.total','--format=csv,noheader,nounits'],\n","                                     capture_output=True, text=True, timeout=5)\n","                if out.returncode==0:\n","                    util, used, total = map(int,out.stdout.strip().split(','))\n","                    print(f\"[GPU] util {util}%  mem {used}/{total} MB\")\n","            except Exception as e:\n","                print(\"[GPU-mon] err\",e)\n","            GPU_MONITOR_STOP.wait(interval)\n","    import threading, atexit\n","    t=threading.Thread(target=_loop,daemon=True); t.start()\n","    atexit.register(GPU_MONITOR_STOP.set)\n","    return t\n"]},{"cell_type":"code","execution_count":3,"id":"d91d385e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1748965309305,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"d91d385e","outputId":"8e4edc22-4367-43ad-8147-bd731496b336"},"outputs":[{"output_type":"stream","name":"stdout","text":["üñ•Ô∏è  CPU 2  ‚Üí workers 4\n"]}],"source":["# --- Adaptive worker counts -------------------------------------------------\n","def configure_workers():\n","    mem = psutil.virtual_memory().available / 2**30\n","    base = min(CPU_COUNT*2, 16)\n","    by_mem = int(mem*0.8)\n","    total = min(base, by_mem, 12)\n","    return max(1,total)\n","\n","MAX_WORKERS = configure_workers()\n","PROGRESS_SAVE_INTERVAL = 5\n","print(f\"üñ•Ô∏è  CPU {CPU_COUNT}  ‚Üí workers {MAX_WORKERS}\")\n"]},{"cell_type":"code","execution_count":5,"id":"767548c2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9730,"status":"ok","timestamp":1748965576889,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"767548c2","outputId":"5ef88cac-fdb9-41a5-89d0-3d2624631b45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","ROOT ‚Üí /content/drive/My Drive/world bank/data/Peru\n"]}],"source":["# --- Drive / paths ----------------------------------------------------------\n","import os\n","from pathlib import Path\n","if IN_COLAB:\n","    from google.colab import drive as _gd; _gd.mount('/content/drive')\n","    ROOT = Path('/content/drive/My Drive/world bank/data/Peru')\n","else:\n","    # For local runs you can set PERU_DATA_ROOT to point to the project directory; defaults to cwd.\n","    ROOT = Path(os.getenv('PERU_DATA_ROOT', Path.cwd()))\n","\n","INPUT_CSV   = ROOT/'evals/formattedData/peru_with_audio_clips.csv'\n","PROGRESS_CSV= ROOT/'evals/formattedData/peru_transcript_progress.csv'\n","FINAL_CSV   = ROOT/'evals/formattedData/peru_with_transcripts.csv'\n","TRANS_DIR   = ROOT/'transcripts/processed'\n","CACHE_DIR   = ROOT/'transcripts/cache'\n","COST_LOG    = ROOT/'transcripts/cost_tracking.json'\n","\n","for p in [TRANS_DIR, CACHE_DIR]:\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","print(\"ROOT ‚Üí\",ROOT)\n"]},{"cell_type":"code","execution_count":6,"id":"5cfad371","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2554,"status":"ok","timestamp":1748965579446,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"5cfad371","outputId":"9dd8ea0d-ea72-46eb-85a1-561b734a5cca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model ‚Üí scribe_v1\n"]}],"source":["# --- ElevenLabs API init ----------------------------------------------------\n","from dotenv import load_dotenv; load_dotenv()\n","from elevenlabs import ElevenLabs\n","import math\n","from pathlib import Path\n","from google.colab import userdata\n","\n","\n","API_KEY = userdata.get('ELEVENLABS_API_KEY')\n","if not API_KEY:\n","    raise RuntimeError('Set ELEVENLABS_API_KEY env var')\n","\n","client = ElevenLabs(api_key=API_KEY)\n","MODEL_ID = 'scribe_v1'\n","print(\"Model ‚Üí\", MODEL_ID)\n","\n","TRANSCRIPTION_PARAMS = dict(\n","    model_id=MODEL_ID,\n","    language_code='spa',      # Spanish\n","    diarize=True,            # enable speaker diarization\n","    timestamps_granularity='word',\n","    tag_audio_events=True\n",")\n","\n","# ElevenLabs bills $0.40 per hour ‚Üí $0.0066667 per minute\n","COST_PER_MIN = 0.0066667\n"]},{"cell_type":"code","execution_count":7,"id":"a2ba6519","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1748965579448,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"a2ba6519"},"outputs":[],"source":["# --- Utility functions for identifier extraction and deduplication ----------\n","def extract_identifier(school_clip):\n","    \"\"\"Extract the 6-7 digit identifier from School_Clip column.\"\"\"\n","    if pd.isna(school_clip) or school_clip == '':\n","        return None\n","    # Extract 6-7 digit number at the start\n","    match = re.match(r'^(\\d{6,7})', str(school_clip).strip())\n","    return match.group(1) if match else None\n","\n","def copy_transcript_data(df, source_idx, target_indices, transcript_column_prefix):\n","    \"\"\"Copy transcript data from source row to target rows.\"\"\"\n","    # All possible columns for this transcript type\n","    columns_to_copy = [\n","        transcript_column_prefix,  # Base transcript column\n","        transcript_column_prefix + '_JSON',\n","        transcript_column_prefix + ' Text',\n","        transcript_column_prefix + ' Language Code',\n","        transcript_column_prefix + ' Language Probability',\n","        transcript_column_prefix + ' Word Count',\n","        transcript_column_prefix + ' Duration Seconds',\n","        transcript_column_prefix + ' Speaker Count',\n","        transcript_column_prefix + ' Has Audio Events',\n","        transcript_column_prefix + ' First Speaker'\n","    ]\n","\n","    for col in columns_to_copy:\n","        if col in df.columns:\n","            source_value = df.at[source_idx, col]\n","            for target_idx in target_indices:\n","                if target_idx != source_idx:  # Don't copy to itself\n","                    df.at[target_idx, col] = source_value\n"]},{"cell_type":"code","execution_count":8,"id":"b2ba6578","metadata":{"executionInfo":{"elapsed":960,"status":"ok","timestamp":1748965580408,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"b2ba6578"},"outputs":[],"source":["# --- Processor class with JSON and column-based storage ---------------------\n","import librosa, soundfile\n","import pandas as pd\n","import json\n","from tqdm.auto import tqdm\n","from datetime import datetime\n","from threading import Lock\n","\n","class TranscriptionProcessor:\n","    def __init__(self):\n","        self.lock = Lock()\n","        self.stats = dict(processed=0, success=0, fail=0, cached=0,\n","                          api_calls=0, cost=0.0, minutes=0.0,\n","                          start=time.time())\n","        self.progress_cnt=0\n","        self.load_cost()\n","\n","    # ---------- cost ledger ----------\n","    def load_cost(self):\n","        try:\n","            if COST_LOG.exists():\n","                self.stats['cost'] = json.loads(COST_LOG.read_text()).get('total_cost',0)\n","                print(\"üí∞ prev cost =\",self.stats['cost'])\n","        except: pass\n","    def flush_cost(self):\n","        COST_LOG.write_text(json.dumps({\n","            'total_cost': self.stats['cost'],\n","            'updated': datetime.now().isoformat()\n","        },indent=2))\n","\n","    # ---------- saving ---------------\n","    def save_progress(self, df, force=False):\n","        with self.lock:\n","            self.progress_cnt += 1\n","            if force or self.progress_cnt>=PROGRESS_SAVE_INTERVAL:\n","                df.to_csv(PROGRESS_CSV, index=False)\n","                self.progress_cnt=0\n","                print(\"üíæ checkpoint saved\", PROGRESS_CSV.name)\n","\n","    # ---------- cache utils ----------\n","    def cache_key(self, path:Path):\n","        s=path.stat()\n","        return hashlib.md5(f\"{path}{s.st_size}{s.st_mtime}\".encode()).hexdigest()\n","\n","    def cache_path(self, path:Path): return CACHE_DIR/f\"{self.cache_key(path)}.json\"\n","\n","    def try_cache(self, path:Path):\n","        cp=self.cache_path(path)\n","        if cp.exists():\n","            try:\n","                return json.loads(cp.read_text())['text']\n","            except: pass\n","        return None\n","\n","    def store_cache(self, path:Path, text:str):\n","        self.cache_path(path).write_text(json.dumps({'text':text,'ts':time.time()}))\n","\n","    def duration_min(self, path:Path):\n","        try:\n","            print(f\"Calculating duration for {path}\")\n","            y,sr=librosa.load(path, sr=None, mono=True)\n","            duration = len(y)/sr/60\n","            print(f\"Calculated duration: {duration}\")\n","            return duration\n","        except Exception as e:\n","            print(f\"ERROR during duration calculation: {e}\")\n","            return max(path.stat().st_size/(1024**2),0.1)\n","\n","    # ---------- JSON storage and metadata extraction ----------\n","    def store_transcript_data(self, df:pd.DataFrame, idx:int, prefix:str, transcript_data:dict):\n","        # Store full JSON response\n","        json_col = prefix + '_JSON'\n","        df.at[idx, json_col] = json.dumps(transcript_data, ensure_ascii=False)\n","        # Store text and key metadata fields\n","        df.at[idx, prefix + ' Text'] = transcript_data.get('text', '')\n","        df.at[idx, prefix + ' Language Code'] = transcript_data.get('language_code', '')\n","        df.at[idx, prefix + ' Language Probability'] = transcript_data.get('language_probability', 0)\n","        words = transcript_data.get('words', [])\n","        df.at[idx, prefix + ' Word Count'] = len([w for w in words if w.get('type') == 'word'])\n","        df.at[idx, prefix + ' Duration Seconds'] = max([w.get('end', 0) for w in words], default=0)\n","        df.at[idx, prefix + ' Speaker Count'] = len(set(w.get('speaker_id') for w in words if w.get('speaker_id')))\n","        df.at[idx, prefix + ' Has Audio Events'] = any(w.get('type') == 'audio_event' for w in words)\n","        df.at[idx, prefix + ' First Speaker'] = next((w.get('speaker_id') for w in words if w.get('type') == 'word'), None)\n","\n","    # ---------- core transcription with JSON response ----------\n","    def transcribe(self, path:Path, retries=0):\n","        print(f\"Processing: {path}\")\n","        print(f\"File exists: {path.exists()}\")\n","        if GPU_SEMAPHORE: GPU_SEMAPHORE.acquire()\n","        try:\n","            cached_text = self.try_cache(path)\n","            if cached_text:\n","                with self.lock: self.stats['cached']+=1\n","                print(\"Result from cache\")\n","                # Returning minimal JSON with text only\n","                return {'text': cached_text, 'language_code':'', 'language_probability':0, 'words':[]}, \"cached\"\n","\n","            dur=self.duration_min(path)\n","            est_cost=dur*COST_PER_MIN\n","            print(\"Calling ElevenLabs API...\")\n","            with open(path,'rb') as f:\n","                resp = client.speech_to_text.convert(file=f, **TRANSCRIPTION_PARAMS)\n","            # Build transcript_data dict\n","            text = resp.text.strip() if hasattr(resp,'text') else str(resp)\n","            transcript_data = {\n","                'language_code': getattr(resp, 'language_code', ''),\n","                'language_probability': getattr(resp, 'language_probability', 0),\n","                'text': text,\n","                'words': []\n","            }\n","            for w in getattr(resp, 'words', []):\n","                transcript_data['words'].append({\n","                    'text': getattr(w, 'text', ''),\n","                    'start': getattr(w, 'start', 0),\n","                    'end': getattr(w, 'end', 0),\n","                    'type': getattr(w, 'type', ''),\n","                    'speaker_id': getattr(w, 'speaker_id', ''),\n","                    'logprob': getattr(w, 'logprob', None)\n","                })\n","            if len(text) < 10:\n","                print(\"Transcript too short, raising\")\n","                raise ValueError(\"too short\")\n","            self.store_cache(path, text)\n","            with self.lock:\n","                self.stats.update(success=self.stats['success']+1,\n","                                  api_calls=self.stats['api_calls']+1,\n","                                  cost=self.stats['cost']+est_cost,\n","                                  minutes=self.stats['minutes']+dur)\n","            print(\"Transcription success\")\n","            return transcript_data, \"ok\"\n","        except Exception as e:\n","            print(f\"ERROR: {type(e).__name__}: {e}\")\n","            if retries < 2:\n","                print(f\"Retrying... attempt {retries+1}\")\n","                time.sleep(2**retries)\n","                return self.transcribe(path, retries+1)\n","            with self.lock: self.stats['fail'] += 1\n","            return None, str(e)\n","        finally:\n","            if GPU_SEMAPHORE: GPU_SEMAPHORE.release()\n"]},{"cell_type":"code","execution_count":9,"id":"b64df76e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5769,"status":"ok","timestamp":1748965586181,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"b64df76e","outputId":"5609a5a7-52ec-42bc-a9cf-0c61f55c9015"},"outputs":[{"output_type":"stream","name":"stdout","text":["Rows 227\n"]}],"source":["# --- Load dataframe and initialize metadata columns ------------------------\n","import pandas as pd, numpy as np\n","\n","df = pd.read_csv(INPUT_CSV)\n","for col in ['First Audio Transcript','Last Audio Transcript']:\n","    # Ensure base transcript columns exist\n","    if col not in df.columns: df[col] = ''\n","    # JSON and metadata columns\n","    df[col + '_JSON'] = ''\n","    df[col + ' Text'] = ''\n","    df[col + ' Language Code'] = ''\n","    df[col + ' Language Probability'] = 0\n","    df[col + ' Word Count'] = 0\n","    df[col + ' Duration Seconds'] = 0\n","    df[col + ' Speaker Count'] = 0\n","    df[col + ' Has Audio Events'] = False\n","    df[col + ' First Speaker'] = None\n","\n","# merge existing progress / final for base and metadata columns\n","for p in [PROGRESS_CSV, FINAL_CSV]:\n","    if p.exists():\n","        df_old = pd.read_csv(p)\n","        for col in ['First Audio Transcript','Last Audio Transcript']:\n","            # Merge base column\n","            if col in df_old.columns:\n","                df[col] = df[col].mask(df[col].eq('') & df_old[col].ne(''), df_old[col])\n","            # Merge metadata columns\n","            for meta_col in [\n","                '_JSON', ' Text', ' Language Code', ' Language Probability',\n","                ' Word Count', ' Duration Seconds', ' Speaker Count',\n","                ' Has Audio Events', ' First Speaker'\n","            ]:\n","                full_col = col + meta_col\n","                if full_col in df_old.columns:\n","                    df[full_col] = df[full_col].mask(df[full_col].eq('') & df_old[full_col].ne(''), df_old[full_col])\n","\n","print(f\"Rows {len(df)}\")"]},{"cell_type":"code","execution_count":10,"id":"a8fc0053","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5032,"status":"ok","timestamp":1748965591211,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"},"user_tz":420},"id":"a8fc0053","outputId":"5f50342e-ee30-467b-dd60-7182a817c10f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 121 unique identifiers (excluding 5 skipped rows)\n","Total rows (original): 227\n","üí∞ prev cost = 10.790180862199183\n","Pending clips 4 (after deduplication)\n","\n","First 5 jobs to process:\n","  1. Identifier 393322: last - world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","     Will copy results to 2 rows: [20, 21]\n","     JSON preview: 'nan'\n","     Text preview: 'nan'\n","  2. Identifier 269860: first - world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","     Will copy results to 2 rows: [163, 164]\n","     JSON preview: 'nan'\n","     Text preview: 'nan'\n","  3. Identifier 247551: last - world bank/data/Peru/audio/processed/247551_Clip_1_last_audio.mp3\n","     Will copy results to 1 rows: [212]\n","     JSON preview: 'nan'\n","     Text preview: 'nan'\n","  4. Identifier 1381979: first - world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","     Will copy results to 1 rows: [225]\n","     JSON preview: 'nan'\n","     Text preview: 'nan'\n","\n","üí∞ Deduplication savings: 15 jobs avoided, ~$1.50 cost saved\n"]}],"source":["# --- Build job list with deduplication logic (with optional skipping of first 5 faulty rows) -------------------------------\n","import pandas as pd\n","import json\n","from collections import defaultdict\n","\n","# Flag to control skipping logic; set to False to include all rows again\n","SKIP_FIRST_N_FAULTY = True\n","N_TO_SKIP = 5\n","\n","def has_valid_transcript(row, col_prefix):\n","    \"\"\"Check if a row has a valid transcript for the given column prefix.\"\"\"\n","    json_col = col_prefix + '_JSON'\n","    text_col = col_prefix + ' Text'\n","\n","    # First check if JSON column exists and has meaningful content\n","    if json_col in row.index:\n","        json_val = row[json_col]\n","        # Check for NaN, empty string, or whitespace-only string\n","        if pd.isna(json_val) or json_val == '' or str(json_val).strip() == '':\n","            return False\n","\n","        # Try to parse the JSON to see if it's valid and has content\n","        try:\n","            json_data = json.loads(str(json_val))\n","            # Check if it has actual text content (not just empty JSON structure)\n","            if 'text' in json_data and json_data['text'] and str(json_data['text']).strip():\n","                return True\n","        except (json.JSONDecodeError, TypeError):\n","            pass\n","\n","    # Fallback: check text column directly\n","    if text_col in row.index:\n","        text_val = row[text_col]\n","        if not pd.isna(text_val) and text_val != '' and str(text_val).strip():\n","            # If we have meaningful text (more than just a few characters), consider it valid\n","            if len(str(text_val).strip()) > 10:\n","                return True\n","\n","    return False\n","\n","# --------------------------------------------------------------------------\n","# Step 1: Identify the first N rows that have no valid transcripts at all\n","# --------------------------------------------------------------------------\n","\n","faulty_indices = []\n","if SKIP_FIRST_N_FAULTY:\n","    for idx, row in df.iterrows():\n","        # A row is \"faulty\" if it has no valid first‚Äêaudio AND no valid last‚Äêaudio transcript\n","        first_ok  = has_valid_transcript(row, 'First Audio Transcript')\n","        last_ok   = has_valid_transcript(row, 'Last Audio Transcript')\n","        if not (first_ok or last_ok):\n","            faulty_indices.append(idx)\n","            if len(faulty_indices) >= N_TO_SKIP:\n","                break\n","\n","# --------------------------------------------------------------------------\n","# Step 2: Build identifier groups, skipping those faulty rows if the flag is True\n","# --------------------------------------------------------------------------\n","\n","identifier_groups = defaultdict(list)\n","for idx, row in df.iterrows():\n","    if SKIP_FIRST_N_FAULTY and idx in faulty_indices:\n","        # Skip this row for now; we'll return to these faulty rows later\n","        continue\n","\n","    school_clip = row.get('School_Clip', '')\n","    identifier = extract_identifier(school_clip)\n","    if identifier:\n","        identifier_groups[identifier].append(idx)\n","\n","print(f\"Found {len(identifier_groups)} unique identifiers (excluding {len(faulty_indices)} skipped rows)\")\n","print(f\"Total rows (original): {len(df)}\")\n","\n","# --------------------------------------------------------------------------\n","# Step 3: Build jobs with deduplication (excluding skipped rows)\n","# --------------------------------------------------------------------------\n","\n","jobs = []\n","processed_combinations = set()  # Track (identifier, clip_type) combinations\n","processor = TranscriptionProcessor()\n","\n","for identifier, row_indices in identifier_groups.items():\n","    # Use the first non‚Äêskipped row as representative\n","    representative_idx = row_indices[0]\n","    representative_row = df.iloc[representative_idx]\n","    ident = representative_row.get('School_Clip', f'row_{representative_idx}')\n","\n","    # Process First Audio Clip if not already handled for this identifier\n","    first_combination = (identifier, 'first')\n","    if first_combination not in processed_combinations:\n","        first_clip = representative_row.get('First Audio Clip', '')\n","        if (first_clip and str(first_clip).strip() != '' and not pd.isna(first_clip)):\n","            # Check if ANY row for this identifier already has a valid transcript\n","            needs_transcription = True\n","            for row_idx in row_indices:\n","                if has_valid_transcript(df.iloc[row_idx], 'First Audio Transcript'):\n","                    needs_transcription = False\n","                    break\n","\n","            if needs_transcription:\n","                jobs.append({\n","                    'idx': representative_idx,\n","                    'ref': first_clip,\n","                    'col': 'First Audio Transcript',\n","                    'ident': ident,\n","                    'ctype': 'first',\n","                    'identifier': identifier,\n","                    'all_row_indices': row_indices\n","                })\n","        processed_combinations.add(first_combination)\n","\n","    # Process Last Audio Clip if not already handled for this identifier\n","    last_combination = (identifier, 'last')\n","    if last_combination not in processed_combinations:\n","        last_clip = representative_row.get('Last Audio Clip', '')\n","        if (last_clip and str(last_clip).strip() != '' and not pd.isna(last_clip)):\n","            # Check if ANY row for this identifier already has a valid transcript\n","            needs_transcription = True\n","            for row_idx in row_indices:\n","                if has_valid_transcript(df.iloc[row_idx], 'Last Audio Transcript'):\n","                    needs_transcription = False\n","                    break\n","\n","            if needs_transcription:\n","                jobs.append({\n","                    'idx': representative_idx,\n","                    'ref': last_clip,\n","                    'col': 'Last Audio Transcript',\n","                    'ident': ident,\n","                    'ctype': 'last',\n","                    'identifier': identifier,\n","                    'all_row_indices': row_indices\n","                })\n","        processed_combinations.add(last_combination)\n","\n","print(f\"Pending clips {len(jobs)} (after deduplication)\")\n","\n","# --------------------------------------------------------------------------\n","# Step 4: Debug / inspect the first few jobs\n","# --------------------------------------------------------------------------\n","\n","if jobs:\n","    print(\"\\nFirst 5 jobs to process:\")\n","    for i, job in enumerate(jobs[:5]):\n","        row = df.iloc[job['idx']]\n","        print(f\"  {i+1}. Identifier {job['identifier']}: {job['ctype']} - {job['ref']}\")\n","        print(f\"     Will copy results to {len(job['all_row_indices'])} rows: {job['all_row_indices']}\")\n","        # Show current state of transcript columns for debugging\n","        json_col = job['col'] + '_JSON'\n","        text_col = job['col'] + ' Text'\n","        json_val = row.get(json_col, 'N/A')\n","        text_val = row.get(text_col, 'N/A')\n","\n","        # Show first 100 chars of JSON and text to see what's there\n","        json_preview = str(json_val)[:100] + \"...\" if len(str(json_val)) > 100 else str(json_val)\n","        text_preview = str(text_val)[:100] + \"...\" if len(str(text_val)) > 100 else str(text_val)\n","\n","        print(f\"     JSON preview: {repr(json_preview)}\")\n","        print(f\"     Text preview: {repr(text_preview)}\")\n","else:\n","    print(\"\\n‚úÖ All transcripts appear to be complete!\")\n","    # Show count of completed transcripts for verification\n","    first_completed = sum(\n","        1\n","        for _, row in df.iterrows()\n","        if row.get('First Audio Clip') and has_valid_transcript(row, 'First Audio Transcript')\n","    )\n","    last_completed = sum(\n","        1\n","        for _, row in df.iterrows()\n","        if row.get('Last Audio Clip') and has_valid_transcript(row, 'Last Audio Transcript')\n","    )\n","    print(f\"  Found {first_completed} completed first audio transcripts\")\n","    print(f\"  Found {last_completed} completed last audio transcripts\")\n","\n","# --------------------------------------------------------------------------\n","# Step 5: Deduplication statistics\n","# --------------------------------------------------------------------------\n","\n","original_potential_jobs = 0\n","for idx, row in df.iterrows():\n","    # Count potential jobs even for skipped rows (so we can compare against jobs after deduplication)\n","    if row.get('First Audio Clip') and not has_valid_transcript(row, 'First Audio Transcript'):\n","        original_potential_jobs += 1\n","    if row.get('Last Audio Clip') and not has_valid_transcript(row, 'Last Audio Transcript'):\n","        original_potential_jobs += 1\n","\n","if original_potential_jobs > len(jobs):\n","    saved_jobs = original_potential_jobs - len(jobs)\n","    saved_cost = saved_jobs * 15 * COST_PER_MIN  # Rough estimate: 15 minutes per clip\n","    print(f\"\\nüí∞ Deduplication savings: {saved_jobs} jobs avoided, ~${saved_cost:.2f} cost saved\")\n","\n","# --------------------------------------------------------------------------\n","# Notes on skipping logic:\n","# - The `SKIP_FIRST_N_FAULTY` flag and `N_TO_SKIP` constants control whether the first N faulty rows are excluded.\n","# - If you later want to include all rows (i.e., remove the skipping logic), set `SKIP_FIRST_N_FAULTY = False`.\n","# - The `faulty_indices` list holds the actual DataFrame indices of the rows that were skipped,\n","#   so you can come back and process them separately when needed.\n"]},{"cell_type":"code","execution_count":11,"id":"1bc53569","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["410a8661fae443e48675048f42a12857","d54e269e17bb4dbcbb59c88886953993","1f49ad013ba44f6d9deb0ce484bcecd9","d5b4e08103d144f0b1aa4dde5caa3e77","caaa9e1990ed428880dd17fe43d33dcc","dc8f2cb671b54677a9a641cf415ca754","2f13ef7811594242a921a9353a16d6b3","8b710baa9402408f98cf64b8f2edd1cc","1e03f1f6bd124090ae8c31aa74d636a4","8dbe7b7388fc443b95337c53ffd4c143","ba863e955ec84060a305ba1ab493ff94"]},"id":"1bc53569","executionInfo":{"status":"ok","timestamp":1748965822564,"user_tz":420,"elapsed":231351,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"}},"outputId":"11abe775-bf71-49e5-b93b-18843f11c43e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/4 [00:00<?, ?clip/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"410a8661fae443e48675048f42a12857"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/247551_Clip_1_last_audio.mp3\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","File exists: True\n","File exists: True\n","File exists: True\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/247551_Clip_1_last_audio.mp3\n","Calculated duration: 14.198857142857143\n","Calling ElevenLabs API...\n","Calculated duration: 24.3024\n","Calling ElevenLabs API...\n","Calculated duration: 30.430400000000002\n","Calling ElevenLabs API...\n","Calculated duration: 47.550399999999996\n","Calling ElevenLabs API...\n","ERROR: ReadTimeout: The read operation timed out\n","Retrying... attempt 1\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","ERROR: ReadTimeout: The read operation timed out\n","Retrying... attempt 1\n","Calculated duration: 14.198857142857143\n","Calling ElevenLabs API...\n","ERROR: ReadTimeout: The read operation timed out\n","Retrying... attempt 1\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/247551_Clip_1_last_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/247551_Clip_1_last_audio.mp3\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","ERROR: ReadTimeout: The read operation timed out\n","Retrying... attempt 1\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","Calculated duration: 24.3024\n","Calling ElevenLabs API...\n","Calculated duration: 30.430400000000002\n","Calling ElevenLabs API...\n","ERROR: ApiError: headers: {'date': 'Tue, 03 Jun 2025 15:48:24 GMT', 'server': 'uvicorn', 'content-length': '387', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': 'd7f7090c5a429457549c5f2a58f0db5f', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'detail': {'status': 'too_many_concurrent_requests', 'message': 'Too many concurrent requests. Your current subscription is associated with a maximum of 20 concurrent requests (running in parallel). This is done such that a single user does not overwhelm our systems and affect other users negatively. Please upgrade your subscription or contact sales if you want to increase this limit.'}}\n","Retrying... attempt 2\n","Calculated duration: 47.550399999999996\n","Calling ElevenLabs API...\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/269860_Clip_1_first_audio.mp3\n","ERROR: ApiError: headers: {'date': 'Tue, 03 Jun 2025 15:48:28 GMT', 'server': 'uvicorn', 'content-length': '387', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': '4a2d230f172f12bf99d9c8b26cd747cb', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'detail': {'status': 'too_many_concurrent_requests', 'message': 'Too many concurrent requests. Your current subscription is associated with a maximum of 20 concurrent requests (running in parallel). This is done such that a single user does not overwhelm our systems and affect other users negatively. Please upgrade your subscription or contact sales if you want to increase this limit.'}}\n","Retrying... attempt 2\n","Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/1381979_Clip_1_first_audio.mp3\n","Calculated duration: 30.430400000000002\n","Calling ElevenLabs API...\n","ERROR: ApiError: headers: {'date': 'Tue, 03 Jun 2025 15:48:35 GMT', 'server': 'uvicorn', 'content-length': '387', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=31536000; includeSubDomains', 'x-trace-id': '84d94f2fb342cf988a98faba5a511c46', 'x-region': 'us-central1', 'via': '1.1 google, 1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 429, body: {'detail': {'status': 'too_many_concurrent_requests', 'message': 'Too many concurrent requests. Your current subscription is associated with a maximum of 20 concurrent requests (running in parallel). This is done such that a single user does not overwhelm our systems and affect other users negatively. Please upgrade your subscription or contact sales if you want to increase this limit.'}}\n","Calculated duration: 47.550399999999996\n","Calling ElevenLabs API...\n","ERROR: ReadTimeout: The read operation timed out\n","Retrying... attempt 2\n","Transcription success\n","‚úÖ Transcribed 247551 last and copied to 1 rows\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-5e0b5631db67>:80: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1458.126' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  df.at[idx, prefix + ' Duration Seconds'] = max([w.get('end', 0) for w in words], default=0)\n"]},{"output_type":"stream","name":"stdout","text":["Processing: /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","File exists: True\n","Calculating duration for /content/drive/My Drive/world bank/data/Peru/audio/processed/393322_Clip_1_last_audio.mp3\n","Calculated duration: 14.198857142857143\n","Calling ElevenLabs API...\n","ERROR: ReadTimeout: The read operation timed out\n","ERROR: ReadTimeout: The read operation timed out\n","üíæ checkpoint saved peru_transcript_progress.csv\n"]}],"source":["# --- Run transcription with copying to duplicate rows ----------------------\n","start = time.time()\n","if jobs:\n","    def worker(job):\n","        if IN_COLAB:\n","            path = Path('/content/drive/My Drive') / job['ref']\n","        else:\n","            path = ROOT / job['ref']\n","\n","        # Transcribe the audio\n","        transcript_data, status = processor.transcribe(path)\n","\n","        if transcript_data:\n","            # Store transcript data in the representative row\n","            processor.store_transcript_data(df, job['idx'], job['col'], transcript_data)\n","\n","            # Copy the transcript data to all other rows with the same identifier\n","            copy_transcript_data(df, job['idx'], job['all_row_indices'], job['col'])\n","\n","            print(f\"‚úÖ Transcribed {job['identifier']} {job['ctype']} and copied to {len(job['all_row_indices'])} rows\")\n","\n","        processor.save_progress(df)\n","        with processor.lock:\n","            processor.stats['processed'] += 1\n","        return job, status\n","\n","    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex, tqdm(total=len(jobs), unit='clip') as bar:\n","        for fut in as_completed([ex.submit(worker, j) for j in jobs]):\n","            job, status = fut.result()\n","            bar.update(1)\n","            bar.set_postfix(proc=processor.stats['processed'], succ=processor.stats['success'],\n","                            cost=f\"${processor.stats['cost']:.2f}\")\n","    processor.save_progress(df, force=True)\n","else:\n","    print(\"Nothing to do ‚Äì all transcripts present\")\n"]},{"cell_type":"code","execution_count":12,"id":"a2fa93cc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2fa93cc","executionInfo":{"status":"ok","timestamp":1748965831705,"user_tz":420,"elapsed":9138,"user":{"displayName":"Matthew Krasnow","userId":"15552423201466358476"}},"outputId":"46816102-066f-429b-c7bb-a518eab5e8c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîç Final verification of transcript coverage...\n","‚ö†Ô∏è  Verification issues found:\n","   Identifier 381855: 1/2 rows have last transcript\n","   Identifier 829457: 1/2 rows have last transcript\n","   Identifier 268516: 1/2 rows have first transcript\n","   Identifier 268516: 1/2 rows have last transcript\n","   Identifier 269779: 1/2 rows have first transcript\n","\n","‚úÖ Saved peru_with_transcripts.csv | rows 227\n","\n","üìä Final Statistics:\n","   Unique identifiers: 121\n","   Total rows: 227\n","   Rows with first transcript: 218\n","   Rows with last transcript: 218\n","   Total API costs: $10.95\n","   Processing time: 240.5 seconds\n"]}],"source":["# --- Final verification and save CSV ---------------------------------------\n","print(\"\\nüîç Final verification of transcript coverage...\")\n","\n","# Count completed transcripts by identifier\n","identifier_transcript_counts = defaultdict(lambda: {'first': 0, 'last': 0, 'rows': 0})\n","\n","for idx, row in df.iterrows():\n","    school_clip = row.get('School_Clip', '')\n","    identifier = extract_identifier(school_clip)\n","    if identifier:\n","        identifier_transcript_counts[identifier]['rows'] += 1\n","\n","        if (row.get('First Audio Clip') and\n","            has_valid_transcript(row, 'First Audio Transcript')):\n","            identifier_transcript_counts[identifier]['first'] += 1\n","\n","        if (row.get('Last Audio Clip') and\n","            has_valid_transcript(row, 'Last Audio Transcript')):\n","            identifier_transcript_counts[identifier]['last'] += 1\n","\n","# Verify that for each identifier, all rows have the same transcript data\n","verification_issues = []\n","for identifier, counts in identifier_transcript_counts.items():\n","    if counts['first'] > 0 and counts['first'] != counts['rows']:\n","        verification_issues.append(f\"Identifier {identifier}: {counts['first']}/{counts['rows']} rows have first transcript\")\n","    if counts['last'] > 0 and counts['last'] != counts['rows']:\n","        verification_issues.append(f\"Identifier {identifier}: {counts['last']}/{counts['rows']} rows have last transcript\")\n","\n","if verification_issues:\n","    print(\"‚ö†Ô∏è  Verification issues found:\")\n","    for issue in verification_issues[:10]:  # Show first 10 issues\n","        print(f\"   {issue}\")\n","    if len(verification_issues) > 10:\n","        print(f\"   ... and {len(verification_issues) - 10} more issues\")\n","else:\n","    print(\"‚úÖ Verification passed: All rows with same identifier have consistent transcript data\")\n","\n","# Save final CSV\n","df.to_csv(FINAL_CSV, index=False)\n","processor.flush_cost()\n","print(f\"\\n‚úÖ Saved {FINAL_CSV.name} | rows {len(df)}\")\n","\n","# Final statistics\n","total_identifiers = len(identifier_groups)\n","total_rows = len(df)\n","completed_first = sum(1 for _, row in df.iterrows()\n","                     if row.get('First Audio Clip') and has_valid_transcript(row, 'First Audio Transcript'))\n","completed_last = sum(1 for _, row in df.iterrows()\n","                    if row.get('Last Audio Clip') and has_valid_transcript(row, 'Last Audio Transcript'))\n","\n","print(f\"\\nüìä Final Statistics:\")\n","print(f\"   Unique identifiers: {total_identifiers}\")\n","print(f\"   Total rows: {total_rows}\")\n","print(f\"   Rows with first transcript: {completed_first}\")\n","print(f\"   Rows with last transcript: {completed_last}\")\n","print(f\"   Total API costs: ${processor.stats['cost']:.2f}\")\n","print(f\"   Processing time: {time.time() - start:.1f} seconds\")\n"]},{"cell_type":"markdown","id":"884babc6","metadata":{"id":"884babc6"},"source":["## üéâ Done!\n","\n","This notebook automatically:\n","1. Detects GPUs and adjusts worker counts.\n","2. Saves progress every 5 successful transcriptions (`peru_transcript_progress.csv`).\n","3. Resumes from either the **progress** or **final** CSV if re-run.\n","4. **Uses ElevenLabs Scribe** for high-accuracy Spanish transcripts with speaker diarization.\n","5. Tracks cumulative ElevenLabs API spend in `cost_tracking.json` at $0.00667 per minute.\n","6. **NEW: Implements identifier-based deduplication** to avoid transcribing the same clips multiple times.\n","\n","### üöÄ Key Deduplication Features:\n","\n","- **Identifier Extraction**: Automatically extracts 6-7 digit identifiers from `School_Clip` column\n","- **Smart Grouping**: Groups rows by identifier and only processes unique audio clips once\n","- **Result Copying**: Automatically copies transcript data to all rows sharing the same identifier\n","- **Cost Savings**: Prevents duplicate API calls, saving significant processing costs\n","- **Verification**: Validates that all rows with the same identifier have consistent transcript data\n","\n","With the updated implementation:\n","- Full JSON responses are stored per-transcript in dedicated `_JSON` columns;\n","- Key metadata (text, language, word counts, durations, speaker info) are extracted into separate columns;\n","- **Deduplication logic prevents wasteful double-transcription of identical clips**;\n","- Existing workflows remain compatible while enabling more detailed analysis.\n","\n","You can safely interrupt and restart without re-transcribing completed audio files, and the deduplication ensures maximum cost efficiency.\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","version":"3.11.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"410a8661fae443e48675048f42a12857":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d54e269e17bb4dbcbb59c88886953993","IPY_MODEL_1f49ad013ba44f6d9deb0ce484bcecd9","IPY_MODEL_d5b4e08103d144f0b1aa4dde5caa3e77"],"layout":"IPY_MODEL_caaa9e1990ed428880dd17fe43d33dcc"}},"d54e269e17bb4dbcbb59c88886953993":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc8f2cb671b54677a9a641cf415ca754","placeholder":"‚Äã","style":"IPY_MODEL_2f13ef7811594242a921a9353a16d6b3","value":"100%"}},"1f49ad013ba44f6d9deb0ce484bcecd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b710baa9402408f98cf64b8f2edd1cc","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e03f1f6bd124090ae8c31aa74d636a4","value":4}},"d5b4e08103d144f0b1aa4dde5caa3e77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dbe7b7388fc443b95337c53ffd4c143","placeholder":"‚Äã","style":"IPY_MODEL_ba863e955ec84060a305ba1ab493ff94","value":"‚Äá4/4‚Äá[03:45&lt;00:00,‚Äá45.33s/clip,‚Äácost=$10.95,‚Äáproc=4,‚Äásucc=1]"}},"caaa9e1990ed428880dd17fe43d33dcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc8f2cb671b54677a9a641cf415ca754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f13ef7811594242a921a9353a16d6b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b710baa9402408f98cf64b8f2edd1cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e03f1f6bd124090ae8c31aa74d636a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8dbe7b7388fc443b95337c53ffd4c143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba863e955ec84060a305ba1ab493ff94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}