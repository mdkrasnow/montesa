{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "373d0e44"
   },
   "source": [
    "# Audio Transcription â€“ Peru Audio Clips  \n",
    "### **GPU-Enhanced, Progress-Aware, Multi-Threaded Pipeline (ElevenLabs Scribe)**\n",
    "\n",
    "This notebook transcribes Spanish MP3 audio clips to **text** **transcripts** using\n",
    "the new **ElevenLabs Scribe v1** Speech-to-Text API, replacing the previous Groq Whisper flow.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Enhancements (relative to the Groq version)**\n",
    "\n",
    "| Area | Upgrade |\n",
    "|------|---------|\n",
    "| STT engine | Switched to ElevenLabs Scribe v1 â€“ 99-language, word-timestamped, speaker-diarized output. |\n",
    "| Diarization | Native `diarize` flag with `num_speakers` hint for up to 32 speakers. |\n",
    "| Spanish mode | `language_code=\"es\"` consistently enforced. |\n",
    "| Cost ledger | Updated to $0.40 h / $0.00667 min pricing. |\n",
    "| API client | Uses the **official `elevenlabs` Python SDK**. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7f463",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# --- Install dependencies ---------------------------------------------------\n",
    "import importlib.util, subprocess, sys, os\n",
    "\n",
    "# Ensure required packages are installed both in Colab and in a local Jupyter environment.\n",
    "pkgs = [\n",
    "    'elevenlabs',\n",
    "    'python-dotenv',\n",
    "    'requests',\n",
    "    'pandas',\n",
    "    'tqdm',\n",
    "    'psutil',\n",
    "    'soundfile',\n",
    "    'librosa'\n",
    "]\n",
    "\n",
    "IN_COLAB = importlib.util.find_spec('google.colab') is not None\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colab: use shell magic for speed and readability\n",
    "    from IPython import get_ipython\n",
    "    get_ipython().system('pip -q install ' + ' '.join(pkgs))\n",
    "else:\n",
    "    # Local: run pip quietly via subprocess (only installs missing packages)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', *pkgs], check=True)\n",
    "\n",
    "print('âœ… Dependencies installed/verified')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9053d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpu_detection"
   },
   "outputs": [],
   "source": [
    "# --- Environment & GPU detection -------------------------------------------\n",
    "import importlib.util, subprocess, os, sys, json, time, hashlib, psutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock, Semaphore, Event\n",
    "\n",
    "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
    "CPU_COUNT = os.cpu_count() or 1\n",
    "CHUNK_SIZE = 8192\n",
    "\n",
    "# GPU detection (unchanged helper)\n",
    "def detect_gpu_and_configure():\n",
    "    gpu = {'available': False, 'memory_gb': 0, 'acceleration_flag': '', 'max_concurrent': 1}\n",
    "    try:\n",
    "        out = subprocess.run(['nvidia-smi','--query-gpu=memory.total','--format=csv,noheader,nounits'],\n",
    "                             capture_output=True, text=True, timeout=10)\n",
    "        if out.returncode==0:\n",
    "            mem_mb=int(out.stdout.strip())\n",
    "            mem_gb=mem_mb/1024\n",
    "            gpu.update({'available': True,\n",
    "                        'memory_gb': mem_gb,\n",
    "                        'acceleration_flag': '-hwaccel cuda',\n",
    "                        'max_concurrent': 4 if mem_gb>=16 else 2 if mem_gb>=8 else 1})\n",
    "            print(f\"ðŸš€ NVIDIA GPU: {mem_gb:.1f} GB - {gpu['max_concurrent']} concurrent heavy tasks\")\n",
    "    except Exception as e:\n",
    "        print(\"No NVIDIA GPU or nvidia-smi failed:\", e)\n",
    "    if not gpu['available']:\n",
    "        print(\"ðŸ’» Using CPU-only mode for local tasks\")\n",
    "    return gpu\n",
    "\n",
    "GPU_INFO = detect_gpu_and_configure()\n",
    "GPU_SEMAPHORE = Semaphore(GPU_INFO['max_concurrent']) if GPU_INFO['available'] else None\n",
    "GPU_MONITOR_STOP = Event()\n",
    "\n",
    "def start_gpu_monitor(interval=60):\n",
    "    if not GPU_INFO['available']: return None\n",
    "    def _loop():\n",
    "        while not GPU_MONITOR_STOP.is_set():\n",
    "            try:\n",
    "                out = subprocess.run(['nvidia-smi','--query-gpu=utilization.gpu,memory.used,memory.total','--format=csv,noheader,nounits'],\n",
    "                                     capture_output=True, text=True, timeout=5)\n",
    "                if out.returncode==0:\n",
    "                    util, used, total = map(int,out.stdout.strip().split(','))\n",
    "                    print(f\"[GPU] util {util}%  mem {used}/{total} MB\")\n",
    "            except Exception as e:\n",
    "                print(\"[GPU-mon] err\",e)\n",
    "            GPU_MONITOR_STOP.wait(interval)\n",
    "    import threading, atexit\n",
    "    t=threading.Thread(target=_loop,daemon=True); t.start()\n",
    "    atexit.register(GPU_MONITOR_STOP.set)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d385e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "worker_cfg"
   },
   "outputs": [],
   "source": [
    "# --- Adaptive worker counts -------------------------------------------------\n",
    "def configure_workers():\n",
    "    mem = psutil.virtual_memory().available / 2**30\n",
    "    base = min(CPU_COUNT*2, 16)\n",
    "    by_mem = int(mem*0.8)\n",
    "    total = min(base, by_mem, 12)\n",
    "    return max(1,total)\n",
    "\n",
    "MAX_WORKERS = configure_workers()\n",
    "PROGRESS_SAVE_INTERVAL = 5\n",
    "print(f\"ðŸ–¥ï¸  CPU {CPU_COUNT}  â†’ workers {MAX_WORKERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767548c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paths"
   },
   "outputs": [],
   "source": [
    "# --- Drive / paths ----------------------------------------------------------\n",
    "import os\n",
    "from pathlib import Path\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive as _gd; _gd.mount('/content/drive')\n",
    "    ROOT = Path('/content/drive/My Drive/world bank/data/Peru')\n",
    "else:\n",
    "    # For local runs you can set PERU_DATA_ROOT to point to the project directory; defaults to cwd.\n",
    "    ROOT = Path(os.getenv('PERU_DATA_ROOT', Path.cwd()))\n",
    "\n",
    "INPUT_CSV   = ROOT/'evals/formattedData/peru_with_audio_clips.csv'\n",
    "PROGRESS_CSV= ROOT/'evals/formattedData/peru_transcript_progress.csv'\n",
    "FINAL_CSV   = ROOT/'evals/formattedData/peru_with_transcripts.csv'\n",
    "TRANS_DIR   = ROOT/'transcripts/processed'\n",
    "CACHE_DIR   = ROOT/'transcripts/cache'\n",
    "COST_LOG    = ROOT/'transcripts/cost_tracking.json'\n",
    "\n",
    "for p in [TRANS_DIR, CACHE_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT â†’\",ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfad371",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eleven_init"
   },
   "outputs": [],
   "source": [
    "# --- ElevenLabs API init ----------------------------------------------------\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "from elevenlabs import ElevenLabs\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "API_KEY = os.getenv('ELEVENLABS_API_KEY')\n",
    "if not API_KEY:\n",
    "    raise RuntimeError('Set ELEVENLABS_API_KEY env var')\n",
    "\n",
    "client = ElevenLabs(api_key=API_KEY)\n",
    "MODEL_ID = 'scribe_v1'\n",
    "print(\"Model â†’\", MODEL_ID)\n",
    "\n",
    "TRANSCRIPTION_PARAMS = dict(\n",
    "    model_id=MODEL_ID,\n",
    "    language_code='es',      # Spanish\n",
    "    diarize=True,            # enable speaker diarization\n",
    "    num_speakers=None,       # adjust if known, else None\n",
    "    timestamps_granularity='word',\n",
    "    tag_audio_events=True\n",
    ")\n",
    "\n",
    "# ElevenLabs bills $0.40 per hour â†’ $0.0066667 per minute\n",
    "COST_PER_MIN = 0.0066667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba6519",
   "metadata": {
    "id": "processor"
   },
   "outputs": [],
   "source": [
    "# --- Processor class with JSON and column-based storage ---------------------\n",
    "import librosa, soundfile\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from threading import Lock\n",
    "\n",
    "class TranscriptionProcessor:\n",
    "    def __init__(self):\n",
    "        self.lock = Lock()\n",
    "        self.stats = dict(processed=0, success=0, fail=0, cached=0,\n",
    "                          api_calls=0, cost=0.0, minutes=0.0,\n",
    "                          start=time.time())\n",
    "        self.progress_cnt=0\n",
    "        self.load_cost()\n",
    "\n",
    "    # ---------- cost ledger ----------\n",
    "    def load_cost(self):\n",
    "        try:\n",
    "            if COST_LOG.exists():\n",
    "                self.stats['cost'] = json.loads(COST_LOG.read_text()).get('total_cost',0)\n",
    "                print(\"ðŸ’° prev cost =\",self.stats['cost'])\n",
    "        except: pass\n",
    "    def flush_cost(self):\n",
    "        COST_LOG.write_text(json.dumps({\n",
    "            'total_cost': self.stats['cost'],\n",
    "            'updated': datetime.now().isoformat()\n",
    "        },indent=2))\n",
    "\n",
    "    # ---------- saving ---------------\n",
    "    def save_progress(self, df, force=False):\n",
    "        with self.lock:\n",
    "            self.progress_cnt += 1\n",
    "            if force or self.progress_cnt>=PROGRESS_SAVE_INTERVAL:\n",
    "                df.to_csv(PROGRESS_CSV, index=False)\n",
    "                self.progress_cnt=0\n",
    "                print(\"ðŸ’¾ checkpoint saved\", PROGRESS_CSV.name)\n",
    "\n",
    "    # ---------- cache utils ----------\n",
    "    def cache_key(self, path:Path):\n",
    "        s=path.stat()\n",
    "        return hashlib.md5(f\"{path}{s.st_size}{s.st_mtime}\".encode()).hexdigest()\n",
    "\n",
    "    def cache_path(self, path:Path): return CACHE_DIR/f\"{self.cache_key(path)}.json\"\n",
    "\n",
    "    def try_cache(self, path:Path):\n",
    "        cp=self.cache_path(path)\n",
    "        if cp.exists():\n",
    "            try:\n",
    "                return json.loads(cp.read_text())['text']\n",
    "            except: pass\n",
    "        return None\n",
    "\n",
    "    def store_cache(self, path:Path, text:str):\n",
    "        self.cache_path(path).write_text(json.dumps({'text':text,'ts':time.time()}))\n",
    "\n",
    "    def duration_min(self, path:Path):\n",
    "        try:\n",
    "            print(f\"Calculating duration for {path}\")\n",
    "            y,sr=librosa.load(path, sr=None, mono=True)\n",
    "            duration = len(y)/sr/60\n",
    "            print(f\"Calculated duration: {duration}\")\n",
    "            return duration\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR during duration calculation: {e}\")\n",
    "            return max(path.stat().st_size/(1024**2),0.1)\n",
    "\n",
    "    # ---------- JSON storage and metadata extraction ----------\n",
    "    def store_transcript_data(self, df:pd.DataFrame, idx:int, prefix:str, transcript_data:dict):\n",
    "        # Store full JSON response\n",
    "        json_col = prefix + '_JSON'\n",
    "        df.at[idx, json_col] = json.dumps(transcript_data, ensure_ascii=False)\n",
    "        # Store text and key metadata fields\n",
    "        df.at[idx, prefix + ' Text'] = transcript_data.get('text', '')\n",
    "        df.at[idx, prefix + ' Language Code'] = transcript_data.get('language_code', '')\n",
    "        df.at[idx, prefix + ' Language Probability'] = transcript_data.get('language_probability', 0)\n",
    "        words = transcript_data.get('words', [])\n",
    "        df.at[idx, prefix + ' Word Count'] = len([w for w in words if w.get('type') == 'word'])\n",
    "        df.at[idx, prefix + ' Duration Seconds'] = max([w.get('end', 0) for w in words], default=0)\n",
    "        df.at[idx, prefix + ' Speaker Count'] = len(set(w.get('speaker_id') for w in words if w.get('speaker_id')))\n",
    "        df.at[idx, prefix + ' Has Audio Events'] = any(w.get('type') == 'audio_event' for w in words)\n",
    "        df.at[idx, prefix + ' First Speaker'] = next((w.get('speaker_id') for w in words if w.get('type') == 'word'), None)\n",
    "\n",
    "    # ---------- core transcription with JSON response ----------\n",
    "    def transcribe(self, path:Path, retries=0):\n",
    "        print(f\"Processing: {path}\")\n",
    "        print(f\"File exists: {path.exists()}\")\n",
    "        if GPU_SEMAPHORE: GPU_SEMAPHORE.acquire()\n",
    "        try:\n",
    "            cached_text = self.try_cache(path)\n",
    "            if cached_text:\n",
    "                with self.lock: self.stats['cached']+=1\n",
    "                print(\"Result from cache\")\n",
    "                # Returning minimal JSON with text only\n",
    "                return {'text': cached_text, 'language_code':'', 'language_probability':0, 'words':[]}, \"cached\"\n",
    "\n",
    "            dur=self.duration_min(path)\n",
    "            est_cost=dur*COST_PER_MIN\n",
    "            print(\"Calling ElevenLabs API...\")\n",
    "            with open(path,'rb') as f:\n",
    "                resp = client.speech_to_text.convert(file=f, **TRANSCRIPTION_PARAMS)\n",
    "            # Build transcript_data dict\n",
    "            text = resp.text.strip() if hasattr(resp,'text') else str(resp)\n",
    "            transcript_data = {\n",
    "                'language_code': getattr(resp, 'language_code', ''),\n",
    "                'language_probability': getattr(resp, 'language_probability', 0),\n",
    "                'text': text,\n",
    "                'words': []\n",
    "            }\n",
    "            for w in getattr(resp, 'words', []):\n",
    "                transcript_data['words'].append({\n",
    "                    'text': getattr(w, 'text', ''),\n",
    "                    'start': getattr(w, 'start', 0),\n",
    "                    'end': getattr(w, 'end', 0),\n",
    "                    'type': getattr(w, 'type', ''),\n",
    "                    'speaker_id': getattr(w, 'speaker_id', ''),\n",
    "                    'logprob': getattr(w, 'logprob', None)\n",
    "                })\n",
    "            if len(text) < 10:\n",
    "                print(\"Transcript too short, raising\")\n",
    "                raise ValueError(\"too short\")\n",
    "            self.store_cache(path, text)\n",
    "            with self.lock:\n",
    "                self.stats.update(success=self.stats['success']+1,\n",
    "                                  api_calls=self.stats['api_calls']+1,\n",
    "                                  cost=self.stats['cost']+est_cost,\n",
    "                                  minutes=self.stats['minutes']+dur)\n",
    "            print(\"Transcription success\")\n",
    "            return transcript_data, \"ok\"\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {type(e).__name__}: {e}\")\n",
    "            if retries < 2:\n",
    "                print(f\"Retrying... attempt {retries+1}\")\n",
    "                time.sleep(2**retries)\n",
    "                return self.transcribe(path, retries+1)\n",
    "            with self.lock: self.stats['fail'] += 1\n",
    "            return None, str(e)\n",
    "        finally:\n",
    "            if GPU_SEMAPHORE: GPU_SEMAPHORE.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64df76e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "load_merge"
   },
   "outputs": [],
   "source": [
    "# --- Load dataframe and initialize metadata columns ------------------------\n",
    "import pandas as pd, numpy as np\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "for col in ['First Audio Transcript','Last Audio Transcript']:\n",
    "    # Ensure base transcript columns exist\n",
    "    if col not in df.columns: df[col] = ''\n",
    "    # JSON and metadata columns\n",
    "    df[col + '_JSON'] = ''\n",
    "    df[col + ' Text'] = ''\n",
    "    df[col + ' Language Code'] = ''\n",
    "    df[col + ' Language Probability'] = 0\n",
    "    df[col + ' Word Count'] = 0\n",
    "    df[col + ' Duration Seconds'] = 0\n",
    "    df[col + ' Speaker Count'] = 0\n",
    "    df[col + ' Has Audio Events'] = False\n",
    "    df[col + ' First Speaker'] = None\n",
    "\n",
    "# merge existing progress / final for base and metadata columns\n",
    "for p in [PROGRESS_CSV, FINAL_CSV]:\n",
    "    if p.exists():\n",
    "        df_old = pd.read_csv(p)\n",
    "        for col in ['First Audio Transcript','Last Audio Transcript']:\n",
    "            # Merge base column\n",
    "            if col in df_old.columns:\n",
    "                df[col] = df[col].mask(df[col].eq('') & df_old[col].ne(''), df_old[col])\n",
    "            # Merge metadata columns\n",
    "            for meta_col in [\n",
    "                '_JSON', ' Text', ' Language Code', ' Language Probability',\n",
    "                ' Word Count', ' Duration Seconds', ' Speaker Count',\n",
    "                ' Has Audio Events', ' First Speaker'\n",
    "            ]:\n",
    "                full_col = col + meta_col\n",
    "                if full_col in df_old.columns:\n",
    "                    df[full_col] = df[full_col].mask(df[full_col].eq('') & df_old[full_col].ne(''), df_old[full_col])\n",
    "\n",
    "print(f\"Rows {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc0053",
   "metadata": {
    "id": "jobs"
   },
   "outputs": [],
   "source": [
    "# --- Build job list ---------------------------------------------------------\n",
    "jobs = []\n",
    "processor = TranscriptionProcessor()\n",
    "for idx, row in df.iterrows():\n",
    "    ident = row.get('School_Clip', f'row_{idx}')\n",
    "    if row['First Audio Clip'] and not row['First Audio Transcript_JSON']:\n",
    "        jobs.append(dict(idx=idx, ref=row['First Audio Clip'], col='First Audio Transcript', ident=ident, ctype='first'))\n",
    "    if row['Last Audio Clip'] and not row['Last Audio Transcript_JSON']:\n",
    "        jobs.append(dict(idx=idx, ref=row['Last Audio Clip'], col='Last Audio Transcript', ident=ident, ctype='last'))\n",
    "\n",
    "print(f\"Pending clips {len(jobs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc53569",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "run"
   },
   "outputs": [],
   "source": [
    "# --- Run transcription ------------------------------------------------------\n",
    "start = time.time()\n",
    "if jobs:\n",
    "    def worker(job):\n",
    "        if IN_COLAB:\n",
    "            path = Path('/content/drive/My Drive') / job['ref']\n",
    "        else:\n",
    "            path = ROOT / job['ref']\n",
    "        transcript_data, status = processor.transcribe(path)\n",
    "        if transcript_data:\n",
    "            processor.store_transcript_data(df, job['idx'], job['col'], transcript_data)\n",
    "        processor.save_progress(df)\n",
    "        with processor.lock:\n",
    "            processor.stats['processed'] += 1\n",
    "        return job, status\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex, tqdm(total=len(jobs), unit='clip') as bar:\n",
    "        for fut in as_completed([ex.submit(worker, j) for j in jobs]):\n",
    "            job, status = fut.result()\n",
    "            bar.update(1)\n",
    "            bar.set_postfix(proc=processor.stats['processed'], succ=processor.stats['success'],\n",
    "                            cost=f\"${processor.stats['cost']:.2f}\")\n",
    "    processor.save_progress(df, force=True)\n",
    "else:\n",
    "    print(\"Nothing to do â€“ all transcripts present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fa93cc",
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "# --- Save final CSV ---------------------------------------------------------\n",
    "df.to_csv(FINAL_CSV, index=False)\n",
    "processor.flush_cost()\n",
    "print(f\"âœ… Saved {FINAL_CSV.name} | rows {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884babc6",
   "metadata": {
    "id": "b011a88a"
   },
   "source": [
    "## ðŸŽ‰ Done!\n",
    "\n",
    "This notebook automatically:\n",
    "1. Detects GPUs and adjusts worker counts.\n",
    "2. Saves progress every 5 successful transcriptions (`peru_transcript_progress.csv`).\n",
    "3. Resumes from either the **progress** or **final** CSV if re-run.\n",
    "4. **Uses ElevenLabs Scribe** for high-accuracy Spanish transcripts with speaker diarization.\n",
    "5. Tracks cumulative ElevenLabs API spend in `cost_tracking.json` at $0.00667 per minute.\n",
    "\n",
    "With the updated implementation:\n",
    "- Full JSON responses are stored per-transcript in dedicated `_JSON` columns;\n",
    "- Key metadata (text, language, word counts, durations, speaker info) are extracted into separate columns;\n",
    "- Existing workflows remain compatible while enabling more detailed analysis.\n",
    "\n",
    "You can safely interrupt and restart without re-transcribing completed audio files.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
