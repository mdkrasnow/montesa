{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fa449f68",
      "metadata": {
        "id": "fa449f68"
      },
      "source": [
        "# Audio Conversion – Peru Video Clips (OPTIMIZED MULTI-THREADED with GPU MANAGEMENT)\n",
        "\n",
        "This notebook converts **SharePoint classroom observation videos** to **MP3 audio clips** for transcription processing. It processes the formatted CSV from the previous step containing `First Video Clip` and `Last Video Clip` URLs.\n",
        "\n",
        "**KEY OPTIMIZATIONS & FIXES:**\n",
        "- **Intelligent GPU management** with proper memory limits and fallback\n",
        "- **Progressive saving** - continuous checkpoint saves to prevent data loss\n",
        "- **Resume capability** - automatically continue from previous runs\n",
        "- **Robust filtering** - only process rows with BOTH video clips\n",
        "- **Resource monitoring** - continuous GPU and system monitoring\n",
        "- **Smart concurrency** - adaptive worker counts based on available resources\n",
        "- **Error resilience** - comprehensive error handling and retry logic\n",
        "\n",
        "**Performance Features:**\n",
        "- Processes multiple videos simultaneously with resource awareness\n",
        "- Uses hardware acceleration when available with proper fallback\n",
        "- Minimizes I/O operations through streaming\n",
        "- Automatic cleanup of temporary files\n",
        "- Intelligent batch sizing based on available resources\n",
        "- Real-time progress persistence every 5 successful conversions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f422af",
      "metadata": {
        "id": "a7f422af"
      },
      "source": [
        "### Workflow\n",
        "1. **Setup**: Install optimized dependencies, mount Google Drive\n",
        "2. **Load Data**: Read formatted CSV with video URLs and merge any existing progress\n",
        "3. **Data Filtering**: Remove any rows that don't have BOTH video clips\n",
        "4. **Authentication**: Reuse SharePoint cookie authentication\n",
        "5. **Resource Detection**: Check for GPU acceleration, determine optimal thread count\n",
        "6. **Resume Logic**: Identify already processed clips and continue from where we left off\n",
        "7. **Concurrent Processing**: Multi-threaded video download + audio extraction with GPU management\n",
        "8. **Progressive Saving**: Save progress every 5 successful conversions\n",
        "9. **Quality Control**: Validate audio files and retry failures\n",
        "10. **Final Output**: Save complete dataset with audio paths\n",
        "\n",
        "**Expected Performance**: ~2-4 videos processed simultaneously depending on GPU memory and bandwidth.\n",
        "**Recovery**: Can resume from any point if interrupted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69303cd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69303cd9",
        "outputId": "8d9ed3c0-6076-4c0e-d6c6-8bcbc897d689"
      },
      "outputs": [],
      "source": [
        "# Install optimized dependencies for audio processing\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq ffmpeg\n",
        "!pip install -q python-dotenv requests pandas tqdm\n",
        "!pip install -q psutil\n",
        "!pip install -q google-auth google-auth-oauthlib google-auth-httplib2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18894582",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18894582",
        "outputId": "2bb07ae2-1c40-4f4b-dd7b-773b60a14a72"
      },
      "outputs": [],
      "source": [
        "# ── ENHANCED Environment Detection & GPU Management Setup ─────────────\n",
        "# -----------------------------------------------------------\n",
        "# Environment Detection & Optimized Setup with GPU Management\n",
        "# -----------------------------------------------------------\n",
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "import tempfile\n",
        "import shutil\n",
        "import psutil\n",
        "import threading\n",
        "from pathlib import Path\n",
        "from urllib.parse import unquote, urlparse\n",
        "from datetime import datetime, timedelta\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from threading import Lock, Semaphore, Event\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import hashlib\n",
        "import numpy as np\n",
        "\n",
        "IN_COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
        "\n",
        "# ── Enhanced Performance Configuration with GPU Management ──────────────\n",
        "CPU_COUNT = os.cpu_count() or 1\n",
        "CHUNK_SIZE = 8192\n",
        "MAX_RETRIES = 3\n",
        "TIMEOUT_SECONDS = 180  # Increased timeout for large files\n",
        "TEMP_CLEANUP_INTERVAL = 25\n",
        "PROGRESS_SAVE_INTERVAL = 5  # Save progress every 5 successful conversions\n",
        "\n",
        "# ── GPU Detection and Memory Management ─────────────────────────────────\n",
        "def detect_gpu_and_configure():\n",
        "    \"\"\"Detect GPU and configure optimal settings based on available VRAM.\"\"\"\n",
        "    gpu_info = {\n",
        "        'available': False,\n",
        "        'memory_gb': 0,\n",
        "        'acceleration_flag': '',\n",
        "        'max_concurrent': 1\n",
        "    }\n",
        "    \n",
        "    # Check for NVIDIA GPU\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'], \n",
        "                              capture_output=True, text=True, timeout=10)\n",
        "        if result.returncode == 0:\n",
        "            memory_mb = int(result.stdout.strip())\n",
        "            memory_gb = memory_mb / 1024\n",
        "            gpu_info.update({\n",
        "                'available': True,\n",
        "                'memory_gb': memory_gb,\n",
        "                'acceleration_flag': '-hwaccel cuda -hwaccel_output_format cuda'\n",
        "            })\n",
        "            \n",
        "            # Configure concurrent GPU processes based on VRAM\n",
        "            if memory_gb >= 16:\n",
        "                gpu_info['max_concurrent'] = 4\n",
        "            elif memory_gb >= 8:\n",
        "                gpu_info['max_concurrent'] = 2\n",
        "            else:\n",
        "                gpu_info['max_concurrent'] = 1\n",
        "                \n",
        "            print(f\"🚀 NVIDIA GPU detected: {memory_gb:.1f} GB VRAM\")\n",
        "            print(f\"⚡ Max concurrent GPU processes: {gpu_info['max_concurrent']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"💻 No NVIDIA GPU detected or nvidia-smi failed: {e}\")\n",
        "    \n",
        "    # Check for Intel Quick Sync if no NVIDIA\n",
        "    if not gpu_info['available']:\n",
        "        try:\n",
        "            result = subprocess.run(['ffmpeg', '-hwaccels'], capture_output=True, text=True, timeout=5)\n",
        "            if 'qsv' in result.stdout:\n",
        "                gpu_info.update({\n",
        "                    'available': True,\n",
        "                    'acceleration_flag': '-hwaccel qsv',\n",
        "                    'max_concurrent': 2\n",
        "                })\n",
        "                print(\"⚡ Intel Quick Sync detected\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    \n",
        "    if not gpu_info['available']:\n",
        "        print(\"💻 No hardware acceleration available – using CPU only\")\n",
        "    \n",
        "    return gpu_info\n",
        "\n",
        "GPU_INFO = detect_gpu_and_configure()\n",
        "\n",
        "# ── Intelligent Worker Configuration ─────────────────────────────────────\n",
        "def configure_optimal_workers():\n",
        "    \"\"\"Configure optimal worker counts based on available resources.\"\"\"\n",
        "    mem = psutil.virtual_memory()\n",
        "    available_gb = mem.available / (1024**3)\n",
        "    \n",
        "    # Base workers on CPU count but limit by memory\n",
        "    base_workers = min(CPU_COUNT * 2, 16)  # More conservative base\n",
        "    \n",
        "    # Adjust for available memory (assume ~1GB per worker)\n",
        "    memory_limited_workers = int(available_gb * 0.8)  # Use 80% of available memory\n",
        "    \n",
        "    total_workers = min(base_workers, memory_limited_workers, 8)  # Cap at 8 total workers\n",
        "    \n",
        "    # GPU workers should be separate and limited\n",
        "    gpu_workers = GPU_INFO['max_concurrent'] if GPU_INFO['available'] else 0\n",
        "    \n",
        "    return max(1, total_workers), max(1, gpu_workers)\n",
        "\n",
        "MAX_WORKERS, GPU_MAX_CONCURRENT = configure_optimal_workers()\n",
        "\n",
        "# ── GPU Resource Management ─────────────────────────────────────────────\n",
        "GPU_SEMAPHORE = Semaphore(GPU_MAX_CONCURRENT) if GPU_INFO['available'] else None\n",
        "GPU_MONITOR_STOP = Event()\n",
        "\n",
        "def start_gpu_monitor(interval_sec: int = 60):\n",
        "    \"\"\"Background thread that monitors GPU utilization and memory usage.\"\"\"\n",
        "    if not GPU_INFO['available'] or 'cuda' not in GPU_INFO.get('acceleration_flag', ''):\n",
        "        return None\n",
        "    \n",
        "    def _monitor():\n",
        "        while not GPU_MONITOR_STOP.is_set():\n",
        "            try:\n",
        "                result = subprocess.run([\n",
        "                    'nvidia-smi', \n",
        "                    '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',\n",
        "                    '--format=csv,noheader,nounits'\n",
        "                ], capture_output=True, text=True, timeout=10)\n",
        "                \n",
        "                if result.returncode == 0:\n",
        "                    util, mem_used, mem_total, temp = result.stdout.strip().split(',')\n",
        "                    util, mem_used, mem_total, temp = int(util), int(mem_used), int(mem_total), int(temp)\n",
        "                    mem_percent = (mem_used / mem_total) * 100\n",
        "                    \n",
        "                    timestamp = time.strftime(\"%H:%M:%S\")\n",
        "                    print(f\"[GPU {timestamp}] Util: {util}% | Memory: {mem_used}/{mem_total} MB ({mem_percent:.1f}%) | Temp: {temp}°C\")\n",
        "                    \n",
        "                    # Warning if GPU memory is getting high\n",
        "                    if mem_percent > 90:\n",
        "                        print(f\"⚠️  GPU memory usage critical: {mem_percent:.1f}%\")\n",
        "                    elif mem_percent > 75:\n",
        "                        print(f\"📊 GPU memory usage high: {mem_percent:.1f}%\")\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"[GPU monitor] Error: {e}\")\n",
        "            \n",
        "            GPU_MONITOR_STOP.wait(interval_sec)\n",
        "    \n",
        "    thread = threading.Thread(target=_monitor, daemon=True)\n",
        "    thread.start()\n",
        "    return thread\n",
        "\n",
        "# ── Resource Information ─────────────────────────────────────────────────\n",
        "def get_system_resources():\n",
        "    \"\"\"Get comprehensive system resource information.\"\"\"\n",
        "    mem = psutil.virtual_memory()\n",
        "    disk = psutil.disk_usage('/')\n",
        "    return {\n",
        "        'memory_percent': mem.percent,\n",
        "        'memory_available_gb': mem.available / 1024**3,\n",
        "        'memory_total_gb': mem.total / 1024**3,\n",
        "        'disk_free_gb': disk.free / 1024**3,\n",
        "        'cpu_count': CPU_COUNT\n",
        "    }\n",
        "\n",
        "resources = get_system_resources()\n",
        "print(\"🖥️  System Resources Configuration\")\n",
        "print(f\"   CPU cores: {resources['cpu_count']} (using {MAX_WORKERS} total workers)\")\n",
        "print(f\"   RAM: {resources['memory_available_gb']:.1f}/{resources['memory_total_gb']:.1f} GB available\")\n",
        "print(f\"   Disk free: {resources['disk_free_gb']:.1f} GB\")\n",
        "print(f\"   GPU acceleration: {GPU_INFO['acceleration_flag'] if GPU_INFO['available'] else 'CPU only'}\")\n",
        "print(f\"   GPU concurrent limit: {GPU_MAX_CONCURRENT}\")\n",
        "\n",
        "# Adjust workers if low on resources\n",
        "if resources['memory_available_gb'] < 4:\n",
        "    MAX_WORKERS = min(MAX_WORKERS, 4)\n",
        "    print(f\"🔧 Reduced total workers to {MAX_WORKERS} due to low RAM\")\n",
        "\n",
        "print(f\"✅ Enhanced setup complete – {MAX_WORKERS} workers with {GPU_MAX_CONCURRENT} GPU slots\")\n",
        "\n",
        "# Start GPU monitoring\n",
        "if GPU_INFO['available']:\n",
        "    gpu_monitor_thread = start_gpu_monitor()\n",
        "    print(\"🔍 GPU monitoring started\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375a4af5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "375a4af5",
        "outputId": "d5d36b6b-d704-49bd-c769-67779df9e65c"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Google Drive Setup and Path Configuration\n",
        "# -----------------------------------------------------------\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive as _gdrive\n",
        "    _gdrive.mount('/content/drive')\n",
        "\n",
        "    # Input paths\n",
        "    DATA_DIR = Path('/content/drive/My Drive/world bank/data/Peru')\n",
        "    INPUT_CSV = DATA_DIR / 'evals/formattedData/peru_formatted_first_last_clips_only.csv'\n",
        "\n",
        "    # Output paths for audio files\n",
        "    AUDIO_OUTPUT_DIR = DATA_DIR / 'audio/processed'\n",
        "    TEMP_DIR = Path('/content/temp_audio')  # Local temp for processing\n",
        "    FINAL_CSV = DATA_DIR / 'evals/formattedData/peru_with_audio_clips.csv'\n",
        "    PROGRESS_CSV = DATA_DIR / 'evals/formattedData/peru_audio_progress.csv'  # Progress checkpoint\n",
        "else:\n",
        "    # Local development paths\n",
        "    NB_DIR = Path.cwd()\n",
        "    DATA_DIR = NB_DIR\n",
        "    INPUT_CSV = DATA_DIR / 'peru_formatted_first_last_clips_only.csv'\n",
        "    AUDIO_OUTPUT_DIR = DATA_DIR / 'audio_output'\n",
        "    TEMP_DIR = Path('temp_audio')\n",
        "    FINAL_CSV = DATA_DIR / 'peru_with_audio_clips.csv'\n",
        "    PROGRESS_CSV = DATA_DIR / 'peru_audio_progress.csv'\n",
        "\n",
        "# Create directories\n",
        "AUDIO_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "TEMP_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "print(\"Running in:\", \"Google Colab\" if IN_COLAB else \"Local Environment\")\n",
        "print(f\"📊 Input CSV: {INPUT_CSV}\")\n",
        "print(f\"🎵 Audio output: {AUDIO_OUTPUT_DIR}\")\n",
        "print(f\"⚡ Temp directory: {TEMP_DIR}\")\n",
        "print(f\"💾 Final CSV: {FINAL_CSV}\")\n",
        "print(f\"🔄 Progress CSV: {PROGRESS_CSV}\")\n",
        "\n",
        "# Verify input file exists\n",
        "if not INPUT_CSV.exists():\n",
        "    print(f\"❌ Input CSV not found: {INPUT_CSV}\")\n",
        "    print(\"🔍 Make sure the previous step (video assignment) completed successfully\")\n",
        "    raise FileNotFoundError(f\"Required input file not found: {INPUT_CSV}\")\n",
        "else:\n",
        "    print(f\"✅ Found input CSV with {sum(1 for _ in open(INPUT_CSV)) - 1} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df63dffe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df63dffe",
        "outputId": "b3c35afa-7c1d-4656-d246-bcb5cdc6122c"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# SharePoint Authentication Setup using Browser Cookies\n",
        "# -----------------------------------------------------------\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Get cookies from environment variable\n",
        "cookie_string = userdata.get('cookie')\n",
        "\n",
        "if not cookie_string:\n",
        "    raise RuntimeError(\"\"\"\n",
        "    ❗ Set 'cookie' environment variable with your browser cookies.\n",
        "\n",
        "    To get cookies:\n",
        "    1. Go to SharePoint site in browser\n",
        "    2. Press F12 → Network tab → Clear → Refresh page\n",
        "    3. Click any request to worldbankgroup.sharepoint.com\n",
        "    4. Copy the complete 'Cookie:' line from Request Headers\n",
        "    5. Set as environment variable: export cookie=\"your_cookie_string\"\n",
        "    \"\"\")\n",
        "\n",
        "# Parse cookies into dictionary\n",
        "cookies = {}\n",
        "for item in cookie_string.split(';'):\n",
        "    if '=' in item:\n",
        "        key, value = item.strip().split('=', 1)\n",
        "        cookies[key] = value\n",
        "\n",
        "print(f\"✅ Loaded {len(cookies)} cookies for SharePoint authentication\")\n",
        "\n",
        "# SharePoint configuration\n",
        "SP_BASE_URL = 'https://worldbankgroup.sharepoint.com/teams/TeachDashboardVideoLibrary-WBGroup'\n",
        "SP_FOLDER_PATH = '/teams/TeachDashboardVideoLibrary-WBGroup/Shared Documents/General/Peru 2019'\n",
        "\n",
        "# Standard headers for SharePoint requests\n",
        "SP_HEADERS = {\n",
        "    'Accept': 'application/json;odata=verbose',\n",
        "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
        "    'Referer': 'https://worldbankgroup.sharepoint.com/'\n",
        "}\n",
        "\n",
        "# Test connection\n",
        "test_url = f\"{SP_BASE_URL}/_api/web\"\n",
        "response = requests.get(test_url, cookies=cookies, headers=SP_HEADERS)\n",
        "print(f\"🔗 SharePoint connection test: {response.status_code}\")\n",
        "\n",
        "if response.status_code == 200:\n",
        "    site_data = response.json()\n",
        "    print(f\"📍 Connected to: {site_data['d']['Title']}\")\n",
        "else:\n",
        "    raise RuntimeError(f\"Failed to connect to SharePoint: {response.status_code} - {response.text[:200]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fd3495d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd3495d",
        "outputId": "456cd921-daa3-4170-b5ab-6d80e2ece1cc"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Enhanced Audio Processor with GPU Management and Progress Persistence\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "class EnhancedAudioProcessor:\n",
        "    \"\"\"High-performance audio processor with GPU management and progress persistence.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        self.session.cookies.update(cookies)\n",
        "        self.session.headers.update(SP_HEADERS)\n",
        "        self.lock = Lock()\n",
        "        self.progress_lock = Lock()\n",
        "        self.stats = {\n",
        "            'processed': 0,\n",
        "            'successful': 0,\n",
        "            'failed': 0,\n",
        "            'gpu_successful': 0,\n",
        "            'cpu_fallback': 0,\n",
        "            'total_size_mb': 0,\n",
        "            'start_time': time.time()\n",
        "        }\n",
        "        self.progress_count = 0\n",
        "\n",
        "    def save_progress(self, df, force=False):\n",
        "        \"\"\"Save progress incrementally to prevent data loss.\"\"\"\n",
        "        with self.progress_lock:\n",
        "            self.progress_count += 1\n",
        "            if force or self.progress_count >= PROGRESS_SAVE_INTERVAL:\n",
        "                try:\n",
        "                    # Add timestamp to track progress\n",
        "                    df_copy = df.copy()\n",
        "                    df_copy['last_progress_save'] = datetime.now().isoformat()\n",
        "                    df_copy.to_csv(PROGRESS_CSV, index=False)\n",
        "                    self.progress_count = 0\n",
        "                    print(f\"💾 Progress saved to {PROGRESS_CSV.name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️  Failed to save progress: {e}\")\n",
        "\n",
        "    def get_video_filename_from_url(self, url):\n",
        "        \"\"\"Extract clean filename from SharePoint URL with better error handling.\"\"\"\n",
        "        try:\n",
        "            if pd.isna(url) or not url or not isinstance(url, str):\n",
        "                raise ValueError(\"Invalid URL\")\n",
        "                \n",
        "            parsed = urlparse(url.strip())\n",
        "            filename = Path(unquote(parsed.path)).name\n",
        "\n",
        "            # Clean filename for filesystem compatibility\n",
        "            filename = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n",
        "\n",
        "            # Ensure it has video extension\n",
        "            valid_extensions = ['.mp4', '.mov', '.avi', '.mts', '.mkv', '.wmv']\n",
        "            if not any(filename.lower().endswith(ext) for ext in valid_extensions):\n",
        "                filename += '.mp4'\n",
        "\n",
        "            return filename\n",
        "        except Exception as e:\n",
        "            # Fallback to hash-based filename\n",
        "            url_hash = hashlib.md5(str(url).encode()).hexdigest()[:8]\n",
        "            return f\"video_{url_hash}.mp4\"\n",
        "\n",
        "    def stream_download_and_extract_audio(self, video_url, output_audio_path, clip_type=\"unknown\"):\n",
        "        \"\"\"Download video and extract audio with enhanced GPU management.\"\"\"\n",
        "        temp_video_path = None\n",
        "\n",
        "        try:\n",
        "            # Validate URL\n",
        "            if pd.isna(video_url) or not video_url or not isinstance(video_url, str):\n",
        "                raise ValueError(\"Invalid video URL\")\n",
        "                \n",
        "            # Create temporary video file\n",
        "            video_filename = self.get_video_filename_from_url(video_url)\n",
        "            temp_video_path = TEMP_DIR / f\"temp_{int(time.time())}_{threading.current_thread().ident}_{video_filename}\"\n",
        "\n",
        "            # Stream download with progress\n",
        "            response = self.session.get(video_url.strip(), stream=True, timeout=TIMEOUT_SECONDS)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded_size = 0\n",
        "\n",
        "            # Stream download to temporary file\n",
        "            with open(temp_video_path, 'wb') as f:\n",
        "                for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        downloaded_size += len(chunk)\n",
        "\n",
        "            # Update stats\n",
        "            with self.lock:\n",
        "                self.stats['total_size_mb'] += downloaded_size / (1024 * 1024)\n",
        "\n",
        "            # Extract audio using ffmpeg with enhanced GPU management\n",
        "            audio_success, used_gpu = self.extract_audio_with_enhanced_gpu_management(\n",
        "                temp_video_path, output_audio_path\n",
        "            )\n",
        "\n",
        "            if audio_success:\n",
        "                with self.lock:\n",
        "                    self.stats['successful'] += 1\n",
        "                    if used_gpu:\n",
        "                        self.stats['gpu_successful'] += 1\n",
        "                    else:\n",
        "                        self.stats['cpu_fallback'] += 1\n",
        "                return True\n",
        "            else:\n",
        "                with self.lock:\n",
        "                    self.stats['failed'] += 1\n",
        "                return False\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"❌ Download failed for {clip_type}: {str(e)[:100]}\")\n",
        "            with self.lock:\n",
        "                self.stats['failed'] += 1\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"💥 Unexpected error for {clip_type}: {str(e)[:100]}\")\n",
        "            with self.lock:\n",
        "                self.stats['failed'] += 1\n",
        "            return False\n",
        "        finally:\n",
        "            # Cleanup temporary video file\n",
        "            if temp_video_path and temp_video_path.exists():\n",
        "                try:\n",
        "                    temp_video_path.unlink()\n",
        "                except:\n",
        "                    pass  # Ignore cleanup errors\n",
        "\n",
        "    def extract_audio_with_enhanced_gpu_management(self, video_path, audio_path):\n",
        "        \"\"\"Extract audio with intelligent GPU management and fallback.\"\"\"\n",
        "        used_gpu = False\n",
        "        \n",
        "        # Build base CPU command\n",
        "        cpu_cmd = [\n",
        "            'ffmpeg', '-y', '-loglevel', 'error',\n",
        "            '-i', str(video_path),\n",
        "            '-vn', '-acodec', 'mp3', '-ab', '128k', \n",
        "            '-avoid_negative_ts', 'make_zero',\n",
        "            str(audio_path)\n",
        "        ]\n",
        "        \n",
        "        # Try GPU first if available\n",
        "        if GPU_INFO['available'] and GPU_SEMAPHORE:\n",
        "            # Acquire GPU slot with timeout\n",
        "            gpu_acquired = GPU_SEMAPHORE.acquire(timeout=30)\n",
        "            if gpu_acquired:\n",
        "                try:\n",
        "                    # Build GPU command with proper error handling\n",
        "                    gpu_cmd = [\n",
        "                        'ffmpeg', '-y', '-loglevel', 'error'\n",
        "                    ] + GPU_INFO['acceleration_flag'].split() + [\n",
        "                        '-i', str(video_path),\n",
        "                        '-vn', '-acodec', 'mp3', '-ab', '128k',\n",
        "                        '-avoid_negative_ts', 'make_zero',\n",
        "                        str(audio_path)\n",
        "                    ]\n",
        "                    \n",
        "                    # Try GPU extraction\n",
        "                    result = subprocess.run(gpu_cmd, capture_output=True, text=True, timeout=TIMEOUT_SECONDS)\n",
        "                    \n",
        "                    if (result.returncode == 0 \n",
        "                            and audio_path.exists() \n",
        "                            and audio_path.stat().st_size > 1000):\n",
        "                        used_gpu = True\n",
        "                        return True, used_gpu\n",
        "                    else:\n",
        "                        # GPU failed, will try CPU\n",
        "                        if result.stderr:\n",
        "                            print(f\"🔄 GPU extraction failed for {audio_path.name}: {result.stderr[:100]}\")\n",
        "                        \n",
        "                except subprocess.TimeoutExpired:\n",
        "                    print(f\"⏱️  GPU ffmpeg timed out for {audio_path.name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"🚫 GPU extraction error for {audio_path.name}: {str(e)[:100]}\")\n",
        "                finally:\n",
        "                    GPU_SEMAPHORE.release()\n",
        "        \n",
        "        # Fallback to CPU\n",
        "        try:\n",
        "            result = subprocess.run(cpu_cmd, capture_output=True, text=True, timeout=TIMEOUT_SECONDS)\n",
        "            if (result.returncode == 0 \n",
        "                    and audio_path.exists() \n",
        "                    and audio_path.stat().st_size > 1000):\n",
        "                return True, used_gpu\n",
        "            else:\n",
        "                if result.stderr:\n",
        "                    print(f\"❌ CPU extraction failed for {audio_path.name}: {result.stderr[:100]}\")\n",
        "                return False, used_gpu\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(f\"⏱️  CPU ffmpeg timed out for {audio_path.name}\")\n",
        "            return False, used_gpu\n",
        "        except Exception as e:\n",
        "            print(f\"💥 CPU extraction error for {audio_path.name}: {str(e)[:100]}\")\n",
        "            return False, used_gpu\n",
        "\n",
        "    def process_single_clip(self, video_url, identifier, clip_type, retry_count=0):\n",
        "        \"\"\"Process a single video clip with enhanced error handling.\"\"\"\n",
        "        # Enhanced URL validation\n",
        "        if pd.isna(video_url) or not video_url or not isinstance(video_url, str) or video_url.strip() == '':\n",
        "            return None\n",
        "\n",
        "        # Generate output filename\n",
        "        clean_identifier = re.sub(r'[^a-zA-Z0-9]', '_', str(identifier))\n",
        "        audio_filename = f\"{clean_identifier}_{clip_type}_audio.mp3\"\n",
        "        audio_path = AUDIO_OUTPUT_DIR / audio_filename\n",
        "\n",
        "        # Check if already exists and is valid\n",
        "        if audio_path.exists() and audio_path.stat().st_size > 1000:\n",
        "            return str(audio_path.relative_to(Path('/content/drive/My Drive') if IN_COLAB else Path.cwd()))\n",
        "\n",
        "        # Process the clip\n",
        "        success = self.stream_download_and_extract_audio(\n",
        "            video_url, audio_path, f\"{identifier}_{clip_type}\"\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            # Return relative path for CSV storage\n",
        "            if IN_COLAB:\n",
        "                return str(audio_path.relative_to(Path('/content/drive/My Drive')))\n",
        "            else:\n",
        "                return str(audio_path.relative_to(Path.cwd()))\n",
        "        elif retry_count < MAX_RETRIES:\n",
        "            print(f\"🔄 Retrying {identifier}_{clip_type} (attempt {retry_count + 1}/{MAX_RETRIES})\")\n",
        "            time.sleep(min(2 ** retry_count, 10))  # Exponential backoff with cap\n",
        "            return self.process_single_clip(video_url, identifier, clip_type, retry_count + 1)\n",
        "        else:\n",
        "            print(f\"❌ Failed to process {identifier}_{clip_type} after {MAX_RETRIES} attempts\")\n",
        "            return None\n",
        "\n",
        "    def get_enhanced_stats(self):\n",
        "        \"\"\"Get enhanced processing statistics including GPU usage.\"\"\"\n",
        "        with self.lock:\n",
        "            elapsed = time.time() - self.stats['start_time']\n",
        "            rate = self.stats['processed'] / elapsed if elapsed > 0 else 0\n",
        "            gpu_percentage = (self.stats['gpu_successful'] / max(1, self.stats['successful'])) * 100\n",
        "            return {\n",
        "                'processed': self.stats['processed'],\n",
        "                'successful': self.stats['successful'],\n",
        "                'failed': self.stats['failed'],\n",
        "                'gpu_successful': self.stats['gpu_successful'],\n",
        "                'cpu_fallback': self.stats['cpu_fallback'],\n",
        "                'gpu_usage_percent': gpu_percentage,\n",
        "                'rate_per_sec': rate,\n",
        "                'total_size_mb': self.stats['total_size_mb'],\n",
        "                'elapsed_sec': elapsed\n",
        "            }\n",
        "\n",
        "    def update_processed_count(self):\n",
        "        \"\"\"Thread-safe increment of processed count.\"\"\"\n",
        "        with self.lock:\n",
        "            self.stats['processed'] += 1\n",
        "\n",
        "print(\"✅ Enhanced audio processor ready with GPU management\")\n",
        "print(f\"🎯 Configured for {MAX_WORKERS} total workers, {GPU_MAX_CONCURRENT} GPU slots\")\n",
        "print(f\"⚡ Hardware acceleration: {GPU_INFO['acceleration_flag'] if GPU_INFO['available'] else 'CPU only'}\")\n",
        "print(f\"💾 Progress will be saved every {PROGRESS_SAVE_INTERVAL} successful conversions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80738e2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80738e2c",
        "outputId": "463fbe61-dbdb-4f92-b40a-0efb80af8b13"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Enhanced Data Loading with Resume Capability\n",
        "# -----------------------------------------------------------\n",
        "print(f\"📊 Loading formatted dataset from: {INPUT_CSV}\")\n",
        "\n",
        "# Load the primary CSV\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "original_row_count = len(df)\n",
        "\n",
        "print(f\"📋 Loaded {len(df)} rows from input CSV\")\n",
        "\n",
        "# *** ENHANCED REQUIREMENT: Remove rows without BOTH video clips ***\n",
        "print(\"🔍 Filtering data to require BOTH video clips...\")\n",
        "\n",
        "# Function to check if value is valid (not NaN, not empty string, not just whitespace)\n",
        "def is_valid_url(value):\n",
        "    return (not pd.isna(value) \n",
        "            and isinstance(value, str) \n",
        "            and value.strip() != '' \n",
        "            and len(value.strip()) > 10)  # Must be reasonably long to be a URL\n",
        "\n",
        "# Filter to keep only rows with both valid video clips\n",
        "valid_first = df['First Video Clip'].apply(is_valid_url)\n",
        "valid_last = df['Last Video Clip'].apply(is_valid_url)\n",
        "both_valid = valid_first & valid_last\n",
        "\n",
        "print(f\"   Rows with valid first video: {valid_first.sum()}\")\n",
        "print(f\"   Rows with valid last video: {valid_last.sum()}\")\n",
        "print(f\"   Rows with BOTH valid videos: {both_valid.sum()}\")\n",
        "print(f\"   Rows to be dropped: {(~both_valid).sum()}\")\n",
        "\n",
        "# Drop rows without both video clips\n",
        "df = df[both_valid].reset_index(drop=True)\n",
        "print(f\"✅ After filtering: {len(df)} rows remain ({len(df)/original_row_count*100:.1f}% of original)\")\n",
        "\n",
        "if len(df) == 0:\n",
        "    raise ValueError(\"No rows remain after filtering for both video clips!\")\n",
        "\n",
        "# *** ENHANCED RESUME LOGIC ***\n",
        "print(\"🔄 Checking for existing progress...\")\n",
        "\n",
        "# Add audio clip columns if they don't exist\n",
        "audio_cols = ['First Audio Clip', 'Last Audio Clip']\n",
        "for col in audio_cols:\n",
        "    if col not in df.columns:\n",
        "        df[col] = ''\n",
        "\n",
        "# Merge with existing progress (priority: progress > final > nothing)\n",
        "progress_merged = False\n",
        "for existing_csv in [PROGRESS_CSV, FINAL_CSV]:\n",
        "    if existing_csv.exists():\n",
        "        try:\n",
        "            print(f\"📂 Found existing file: {existing_csv.name}\")\n",
        "            df_existing = pd.read_csv(existing_csv)\n",
        "            \n",
        "            # Merge audio clip data based on a key (assuming there's an identifier)\n",
        "            # Use index-based merging if no unique identifier is available\n",
        "            if 'School_Clip' in df.columns and 'School_Clip' in df_existing.columns:\n",
        "                # Merge on School_Clip identifier\n",
        "                for col in audio_cols:\n",
        "                    if col in df_existing.columns:\n",
        "                        df = df.merge(\n",
        "                            df_existing[['School_Clip', col]].rename(columns={col: f'{col}_existing'}),\n",
        "                            on='School_Clip',\n",
        "                            how='left'\n",
        "                        )\n",
        "                        # Update with existing values where current is empty\n",
        "                        mask = (df[col].fillna('').str.strip() == '') & (df[f'{col}_existing'].fillna('').str.strip() != '')\n",
        "                        df.loc[mask, col] = df.loc[mask, f'{col}_existing']\n",
        "                        df = df.drop(columns=[f'{col}_existing'])\n",
        "            else:\n",
        "                # Index-based merging (less reliable but better than nothing)\n",
        "                for col in audio_cols:\n",
        "                    if col in df_existing.columns:\n",
        "                        for idx in df.index:\n",
        "                            if idx < len(df_existing):\n",
        "                                existing_value = df_existing.loc[idx, col]\n",
        "                                current_value = df.loc[idx, col]\n",
        "                                if (pd.isna(current_value) or current_value == '') and not pd.isna(existing_value) and existing_value != '':\n",
        "                                    df.loc[idx, col] = existing_value\n",
        "            \n",
        "            progress_merged = True\n",
        "            print(f\"✅ Merged progress from {existing_csv.name}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️  Could not merge from {existing_csv.name}: {e}\")\n",
        "\n",
        "if not progress_merged:\n",
        "    print(\"🆕 Starting fresh - no existing progress found\")\n",
        "\n",
        "# Check required columns\n",
        "required_cols = ['First Video Clip', 'Last Video Clip']\n",
        "missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "if missing_cols:\n",
        "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
        "\n",
        "# *** ENHANCED WORKLOAD ANALYSIS ***\n",
        "print(\"\\n📊 Enhanced Workload Analysis:\")\n",
        "\n",
        "# Analyze existing progress\n",
        "def is_valid_audio_path(value):\n",
        "    if pd.isna(value) or not isinstance(value, str) or value.strip() == '':\n",
        "        return False\n",
        "    # Check if file actually exists\n",
        "    try:\n",
        "        if IN_COLAB:\n",
        "            full_path = Path('/content/drive/My Drive') / value\n",
        "        else:\n",
        "            full_path = Path.cwd() / value\n",
        "        return full_path.exists() and full_path.stat().st_size > 1000\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "already_done_first = df['First Audio Clip'].apply(is_valid_audio_path).sum()\n",
        "already_done_last = df['Last Audio Clip'].apply(is_valid_audio_path).sum()\n",
        "\n",
        "print(f\"   Total rows (both videos): {len(df)}\")\n",
        "print(f\"   Already completed first audio: {already_done_first}\")\n",
        "print(f\"   Already completed last audio: {already_done_last}\")\n",
        "print(f\"   Progress: First {already_done_first}/{len(df)} ({already_done_first/len(df)*100:.1f}%)\")\n",
        "print(f\"   Progress: Last {already_done_last}/{len(df)} ({already_done_last/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Calculate clips still to process\n",
        "clips_to_process = []\n",
        "for idx, row in df.iterrows():\n",
        "    identifier = row.get('School_Clip', f'row_{idx}')\n",
        "    \n",
        "    if not is_valid_audio_path(row['First Audio Clip']):\n",
        "        clips_to_process.append({\n",
        "            'idx': idx,\n",
        "            'identifier': identifier,\n",
        "            'video_url': row['First Video Clip'],\n",
        "            'clip_type': 'first',\n",
        "            'audio_col': 'First Audio Clip'\n",
        "        })\n",
        "\n",
        "    if not is_valid_audio_path(row['Last Audio Clip']):\n",
        "        clips_to_process.append({\n",
        "            'idx': idx,\n",
        "            'identifier': identifier,\n",
        "            'video_url': row['Last Video Clip'],\n",
        "            'clip_type': 'last',\n",
        "            'audio_col': 'Last Audio Clip'\n",
        "        })\n",
        "\n",
        "print(f\"\\n🎯 Clips remaining to process: {len(clips_to_process)}\")\n",
        "total_possible = len(df) * 2\n",
        "completed = total_possible - len(clips_to_process)\n",
        "print(f\"   Overall completion: {completed}/{total_possible} ({completed/total_possible*100:.1f}%)\")\n",
        "\n",
        "if len(clips_to_process) == 0:\n",
        "    print(\"✅ All clips already processed! No work needed.\")\n",
        "else:\n",
        "    # Estimate processing time\n",
        "    estimated_time_per_clip = 45  # More conservative estimate\n",
        "    estimated_total_seconds = (len(clips_to_process) * estimated_time_per_clip) / MAX_WORKERS\n",
        "    estimated_total_minutes = estimated_total_seconds / 60\n",
        "\n",
        "    print(f\"⏱️  Estimated processing time: {estimated_total_minutes:.1f} minutes\")\n",
        "    print(f\"📊 Using {MAX_WORKERS} total workers with {GPU_MAX_CONCURRENT} GPU slots\")\n",
        "\n",
        "    # Show sample clips\n",
        "    print(f\"\\n📋 Sample clips to process:\")\n",
        "    for i, clip in enumerate(clips_to_process[:5]):\n",
        "        print(f\"   {i+1}. {clip['identifier']} - {clip['clip_type']} clip\")\n",
        "\n",
        "    if len(clips_to_process) > 5:\n",
        "        print(f\"   ... and {len(clips_to_process) - 5} more clips\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726aac6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "428148746f514c87905d494d7247687a",
            "0c3cb9e4a9e3483f96194e51aa5d0121",
            "8ea4d3b23be4483880a78c11a7386425",
            "c35dd6cde24b4be293cdfa3df07568af",
            "3c4419f743914cba92cbbf165108937f",
            "4709c80dd65c4e72affcf6c692b17fee",
            "d39b61ec11a6487ab403324a74ddde27",
            "dc8619af1bdd47a3b658fac07d29d99f",
            "483c95b97af34461bf569df621f3d18b",
            "9635bc3c4e4c4235a1816aeea704d294",
            "11148a25b168400990f11ca57f533876"
          ]
        },
        "id": "726aac6d",
        "outputId": "bdfe0836-7179-4f00-fb17-02e7dcc0178b"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Enhanced Concurrent Audio Processing with Progress Persistence\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "if len(clips_to_process) > 0:\n",
        "    print(\"=\"*80)\n",
        "    print(\"🚀 STARTING ENHANCED AUDIO CONVERSION WITH GPU MANAGEMENT\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"📹 Processing {len(clips_to_process)} video clips\")\n",
        "    print(f\"⚡ Total workers: {MAX_WORKERS} | GPU slots: {GPU_MAX_CONCURRENT}\")\n",
        "    print(f\"🔧 Hardware acceleration: {GPU_INFO['acceleration_flag'] if GPU_INFO['available'] else 'CPU only'}\")\n",
        "    print(f\"💾 Progress saves every {PROGRESS_SAVE_INTERVAL} successful conversions\")\n",
        "    print(f\"📁 Output directory: {AUDIO_OUTPUT_DIR}\")\n",
        "    print()\n",
        "\n",
        "    # Initialize enhanced processor\n",
        "    processor = EnhancedAudioProcessor()\n",
        "\n",
        "    def process_clip_wrapper(clip_info):\n",
        "        \"\"\"Enhanced wrapper function for concurrent processing with better error handling.\"\"\"\n",
        "        thread_id = threading.current_thread().ident\n",
        "        try:\n",
        "            result = processor.process_single_clip(\n",
        "                clip_info['video_url'],\n",
        "                clip_info['identifier'],\n",
        "                clip_info['clip_type']\n",
        "            )\n",
        "            processor.update_processed_count()\n",
        "            \n",
        "            success_result = {\n",
        "                'idx': clip_info['idx'],\n",
        "                'audio_col': clip_info['audio_col'],\n",
        "                'audio_path': result,\n",
        "                'success': result is not None,\n",
        "                'identifier': clip_info['identifier'],\n",
        "                'clip_type': clip_info['clip_type'],\n",
        "                'thread_id': thread_id\n",
        "            }\n",
        "            \n",
        "            # Update DataFrame immediately for successful conversions\n",
        "            if result is not None:\n",
        "                df.at[clip_info['idx'], clip_info['audio_col']] = result\n",
        "                processor.save_progress(df)  # This handles the interval internally\n",
        "            \n",
        "            return success_result\n",
        "            \n",
        "        except Exception as e:\n",
        "            processor.update_processed_count()\n",
        "            print(f\"💥 Critical error processing {clip_info['identifier']}_{clip_info['clip_type']}: {e}\")\n",
        "            return {\n",
        "                'idx': clip_info['idx'],\n",
        "                'audio_col': clip_info['audio_col'],\n",
        "                'audio_path': None,\n",
        "                'success': False,\n",
        "                'identifier': clip_info['identifier'],\n",
        "                'clip_type': clip_info['clip_type'],\n",
        "                'error': str(e),\n",
        "                'thread_id': thread_id\n",
        "            }\n",
        "\n",
        "    # Process clips concurrently with enhanced progress tracking\n",
        "    start_time = time.time()\n",
        "    results = []\n",
        "    last_stats_time = start_time\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        # Submit all tasks\n",
        "        future_to_clip = {executor.submit(process_clip_wrapper, clip): clip for clip in clips_to_process}\n",
        "\n",
        "        # Process completed tasks with enhanced progress bar\n",
        "        with tqdm(total=len(clips_to_process), desc=\"Converting videos to audio\", unit=\"clip\") as pbar:\n",
        "            for future in as_completed(future_to_clip):\n",
        "                result = future.result()\n",
        "                results.append(result)\n",
        "\n",
        "                # Enhanced progress bar updates\n",
        "                current_stats = processor.get_enhanced_stats()\n",
        "                \n",
        "                if result['success']:\n",
        "                    pbar.set_postfix({\n",
        "                        'Success': f\"{current_stats['successful']}/{len(results)}\",\n",
        "                        'GPU': f\"{current_stats['gpu_successful']}\",\n",
        "                        'Rate': f\"{current_stats['rate_per_sec']:.1f}/s\",\n",
        "                        'Current': f\"{result['identifier']}_{result['clip_type']}\"\n",
        "                    })\n",
        "                else:\n",
        "                    pbar.set_postfix({\n",
        "                        'Failed': f\"{current_stats['failed']}/{len(results)}\",\n",
        "                        'Current': f\"FAILED: {result['identifier']}_{result['clip_type']}\"\n",
        "                    })\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "                # Periodic detailed stats (every 2 minutes)\n",
        "                current_time = time.time()\n",
        "                if current_time - last_stats_time > 120:\n",
        "                    stats = processor.get_enhanced_stats()\n",
        "                    print(f\"\\n📊 Status Update - GPU: {stats['gpu_usage_percent']:.1f}% | \"\n",
        "                          f\"Rate: {stats['rate_per_sec']:.2f} clips/sec | \"\n",
        "                          f\"Data: {stats['total_size_mb']:.1f} MB\")\n",
        "                    last_stats_time = current_time\n",
        "\n",
        "                # Periodic cleanup of temp files\n",
        "                if len(results) % TEMP_CLEANUP_INTERVAL == 0:\n",
        "                    try:\n",
        "                        for temp_file in TEMP_DIR.glob('temp_*'):\n",
        "                            if temp_file.stat().st_mtime < time.time() - 300:  # 5 minutes old\n",
        "                                temp_file.unlink()\n",
        "                    except:\n",
        "                        pass  # Ignore cleanup errors\n",
        "\n",
        "    # Force final progress save\n",
        "    processor.save_progress(df, force=True)\n",
        "\n",
        "    # Processing complete - analyze results\n",
        "    elapsed_time = time.time() - start_time\n",
        "    successful_results = [r for r in results if r['success']]\n",
        "    failed_results = [r for r in results if not r['success']]\n",
        "    final_stats = processor.get_enhanced_stats()\n",
        "\n",
        "    print()\n",
        "    print(\"=\"*80)\n",
        "    print(\"📊 ENHANCED AUDIO CONVERSION COMPLETE - PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"✅ Successfully converted: {len(successful_results)}/{len(clips_to_process)} clips\")\n",
        "    print(f\"❌ Failed conversions: {len(failed_results)}\")\n",
        "    print(f\"⏱️  Total processing time: {elapsed_time/60:.1f} minutes\")\n",
        "    print(f\"🚀 Average rate: {len(clips_to_process)/elapsed_time:.2f} clips/second\")\n",
        "    print(f\"📊 Total data processed: {final_stats['total_size_mb']:.1f} MB\")\n",
        "    print(f\"⚡ GPU acceleration usage: {final_stats['gpu_usage_percent']:.1f}%\")\n",
        "    print(f\"🖥️  GPU successful: {final_stats['gpu_successful']} | CPU fallback: {final_stats['cpu_fallback']}\")\n",
        "\n",
        "    if len(successful_results) > 0:\n",
        "        avg_size = final_stats['total_size_mb'] / len(successful_results)\n",
        "        print(f\"💾 Average file size: {avg_size:.2f} MB/clip\")\n",
        "\n",
        "    if failed_results:\n",
        "        print(f\"\\n❌ Failed clips (first 5):\")\n",
        "        for fail in failed_results[:5]:\n",
        "            error_msg = fail.get('error', 'Unknown error')\n",
        "            print(f\"   {fail['identifier']}_{fail['clip_type']}: {error_msg[:80]}\")\n",
        "        if len(failed_results) > 5:\n",
        "            print(f\"   ... and {len(failed_results) - 5} more failures\")\n",
        "\n",
        "    # Show sample successful conversions\n",
        "    if successful_results:\n",
        "        print(f\"\\n✅ Sample successful conversions:\")\n",
        "        for success in successful_results[:3]:\n",
        "            audio_file = AUDIO_OUTPUT_DIR / Path(success['audio_path']).name\n",
        "            if audio_file.exists():\n",
        "                size_mb = audio_file.stat().st_size / (1024 * 1024)\n",
        "                print(f\"   {success['identifier']}_{success['clip_type']}: {size_mb:.2f} MB\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "else:\n",
        "    print(\"✅ No clips to process - all conversions already completed!\")\n",
        "    results = []\n",
        "\n",
        "# Stop GPU monitoring\n",
        "if GPU_INFO['available']:\n",
        "    GPU_MONITOR_STOP.set()\n",
        "    print(\"🔍 GPU monitoring stopped\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2b1d4e",
      "metadata": {
        "id": "fe2b1d4e"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Enhanced Quality Control and Validation\n",
        "# -----------------------------------------------------------\n",
        "print(\"🔍 Performing enhanced quality control on audio files...\")\n",
        "\n",
        "# Enhanced validation with file integrity checks\n",
        "validation_stats = {\n",
        "    'total_audio_refs': 0,\n",
        "    'valid_files': 0,\n",
        "    'missing_files': 0,\n",
        "    'empty_files': 0,\n",
        "    'corrupted_files': 0,\n",
        "    'total_size_mb': 0,\n",
        "    'size_distribution': []\n",
        "}\n",
        "\n",
        "missing_files = []\n",
        "valid_files = []\n",
        "corrupted_files = []\n",
        "\n",
        "def validate_audio_file(audio_path):\n",
        "    \"\"\"Enhanced audio file validation including basic integrity check.\"\"\"\n",
        "    if not audio_path.exists():\n",
        "        return 'missing'\n",
        "    \n",
        "    file_size = audio_path.stat().st_size\n",
        "    if file_size < 1000:  # Less than 1KB\n",
        "        return 'empty'\n",
        "    \n",
        "    # Basic integrity check - try to read the first few bytes\n",
        "    try:\n",
        "        with open(audio_path, 'rb') as f:\n",
        "            header = f.read(10)\n",
        "            # Check for MP3 header (ID3 tag or MP3 frame)\n",
        "            if not (header.startswith(b'ID3') or header[0:2] == b'\\xff\\xfb' or header[0:2] == b'\\xff\\xf3'):\n",
        "                # Not a standard MP3 header, but might still be valid\n",
        "                pass\n",
        "        return 'valid'\n",
        "    except Exception:\n",
        "        return 'corrupted'\n",
        "\n",
        "for col in ['First Audio Clip', 'Last Audio Clip']:\n",
        "    for idx, row in df.iterrows():\n",
        "        audio_ref = row[col]\n",
        "        if audio_ref and not pd.isna(audio_ref) and str(audio_ref).strip():\n",
        "            validation_stats['total_audio_refs'] += 1\n",
        "\n",
        "            # Construct full path\n",
        "            if IN_COLAB:\n",
        "                audio_path = Path('/content/drive/My Drive') / audio_ref\n",
        "            else:\n",
        "                audio_path = Path.cwd() / audio_ref\n",
        "\n",
        "            validation_result = validate_audio_file(audio_path)\n",
        "            \n",
        "            if validation_result == 'valid':\n",
        "                file_size = audio_path.stat().st_size\n",
        "                size_mb = file_size / (1024 * 1024)\n",
        "                \n",
        "                validation_stats['valid_files'] += 1\n",
        "                validation_stats['total_size_mb'] += size_mb\n",
        "                validation_stats['size_distribution'].append(size_mb)\n",
        "                \n",
        "                valid_files.append({\n",
        "                    'path': audio_path,\n",
        "                    'size_mb': size_mb,\n",
        "                    'row': idx,\n",
        "                    'column': col\n",
        "                })\n",
        "            else:\n",
        "                # Handle invalid files\n",
        "                if validation_result == 'missing':\n",
        "                    validation_stats['missing_files'] += 1\n",
        "                    missing_files.append(f\"Missing: {audio_ref} (row {idx})\")\n",
        "                elif validation_result == 'empty':\n",
        "                    validation_stats['empty_files'] += 1\n",
        "                    missing_files.append(f\"Empty file: {audio_ref} (row {idx})\")\n",
        "                elif validation_result == 'corrupted':\n",
        "                    validation_stats['corrupted_files'] += 1\n",
        "                    corrupted_files.append(f\"Corrupted: {audio_ref} (row {idx})\")\n",
        "                \n",
        "                # Clear invalid reference\n",
        "                df.at[idx, col] = ''\n",
        "\n",
        "# Calculate size distribution statistics\n",
        "if validation_stats['size_distribution']:\n",
        "    sizes = validation_stats['size_distribution']\n",
        "    size_stats = {\n",
        "        'min': min(sizes),\n",
        "        'max': max(sizes),\n",
        "        'mean': sum(sizes) / len(sizes),\n",
        "        'median': sorted(sizes)[len(sizes)//2] if sizes else 0\n",
        "    }\n",
        "else:\n",
        "    size_stats = {'min': 0, 'max': 0, 'mean': 0, 'median': 0}\n",
        "\n",
        "print(f\"\\n📊 Enhanced Quality Control Results:\")\n",
        "print(f\"   Total audio references: {validation_stats['total_audio_refs']}\")\n",
        "print(f\"   ✅ Valid files: {validation_stats['valid_files']}\")\n",
        "print(f\"   ❌ Missing files: {validation_stats['missing_files']}\")\n",
        "print(f\"   🚫 Empty files: {validation_stats['empty_files']}\")\n",
        "print(f\"   💥 Corrupted files: {validation_stats['corrupted_files']}\")\n",
        "print(f\"   💾 Total audio size: {validation_stats['total_size_mb']:.1f} MB\")\n",
        "print(f\"   📈 File size stats: min={size_stats['min']:.2f}MB, max={size_stats['max']:.2f}MB, avg={size_stats['mean']:.2f}MB\")\n",
        "\n",
        "# Show validation issues if any\n",
        "all_issues = missing_files + corrupted_files\n",
        "if all_issues:\n",
        "    print(f\"\\n⚠️  Validation Issues (first 10):\")\n",
        "    for issue in all_issues[:10]:\n",
        "        print(f\"   {issue}\")\n",
        "    if len(all_issues) > 10:\n",
        "        print(f\"   ... and {len(all_issues) - 10} more issues\")\n",
        "\n",
        "# Sample valid files with size distribution\n",
        "if valid_files:\n",
        "    print(f\"\\n✅ Sample valid audio files:\")\n",
        "    # Sort by size for better representation\n",
        "    valid_files_sorted = sorted(valid_files, key=lambda x: x['size_mb'])\n",
        "    sample_indices = [0, len(valid_files_sorted)//2, -1] if len(valid_files_sorted) > 2 else range(len(valid_files_sorted))\n",
        "    \n",
        "    for i in sample_indices:\n",
        "        if i < len(valid_files_sorted):\n",
        "            vf = valid_files_sorted[i]\n",
        "            print(f\"   {vf['path'].name}: {vf['size_mb']:.2f} MB (row {vf['row']}, {vf['column']})\")\n",
        "\n",
        "# Calculate enhanced coverage statistics\n",
        "def has_valid_audio(value):\n",
        "    return value and not pd.isna(value) and str(value).strip() != ''\n",
        "\n",
        "coverage_stats = {\n",
        "    'rows_with_first_audio': df['First Audio Clip'].apply(has_valid_audio).sum(),\n",
        "    'rows_with_last_audio': df['Last Audio Clip'].apply(has_valid_audio).sum(),\n",
        "    'rows_with_both_audio': (df['First Audio Clip'].apply(has_valid_audio) & df['Last Audio Clip'].apply(has_valid_audio)).sum(),\n",
        "    'rows_with_any_audio': (df['First Audio Clip'].apply(has_valid_audio) | df['Last Audio Clip'].apply(has_valid_audio)).sum()\n",
        "}\n",
        "\n",
        "print(f\"\\n📈 Final Audio Coverage:\")\n",
        "print(f\"   Rows with first audio: {coverage_stats['rows_with_first_audio']}/{len(df)} ({coverage_stats['rows_with_first_audio']/len(df)*100:.1f}%)\")\n",
        "print(f\"   Rows with last audio: {coverage_stats['rows_with_last_audio']}/{len(df)} ({coverage_stats['rows_with_last_audio']/len(df)*100:.1f}%)\")\n",
        "print(f\"   Rows with both audio: {coverage_stats['rows_with_both_audio']}/{len(df)} ({coverage_stats['rows_with_both_audio']/len(df)*100:.1f}%)\")\n",
        "print(f\"   Rows with any audio: {coverage_stats['rows_with_any_audio']}/{len(df)} ({coverage_stats['rows_with_any_audio']/len(df)*100:.1f}%)\")\n",
        "\n",
        "print(\"✅ Enhanced quality control complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d98071c",
      "metadata": {
        "id": "9d98071c"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Enhanced Final Dataset Saving with Comprehensive Metadata\n",
        "# -----------------------------------------------------------\n",
        "print(f\"💾 Saving enhanced final dataset with audio clips and metadata...\")\n",
        "\n",
        "# Add comprehensive processing metadata\n",
        "current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "processing_metadata = {\n",
        "    'timestamp': current_timestamp,\n",
        "    'gpu_available': GPU_INFO['available'],\n",
        "    'gpu_acceleration': GPU_INFO['acceleration_flag'],\n",
        "    'workers_used': MAX_WORKERS,\n",
        "    'gpu_slots_used': GPU_MAX_CONCURRENT,\n",
        "    'valid_audio_files': validation_stats['valid_files'],\n",
        "    'total_audio_size_mb': validation_stats['total_size_mb'],\n",
        "    'original_rows': original_row_count,\n",
        "    'filtered_rows': len(df)\n",
        "}\n",
        "\n",
        "# Create processing summary for context column\n",
        "processing_summary = (f\"AUDIO_CONVERSION_ENHANCED: {current_timestamp} | \"\n",
        "                     f\"{validation_stats['valid_files']} valid files | \"\n",
        "                     f\"GPU: {GPU_INFO['acceleration_flag'] if GPU_INFO['available'] else 'CPU'} | \"\n",
        "                     f\"Workers: {MAX_WORKERS} | \"\n",
        "                     f\"Size: {validation_stats['total_size_mb']:.1f}MB\")\n",
        "\n",
        "# Add processing context to rows with audio\n",
        "for idx, row in df.iterrows():\n",
        "    if has_valid_audio(row['First Audio Clip']) or has_valid_audio(row['Last Audio Clip']):\n",
        "        existing_context = str(row.get('Context', ''))\n",
        "        # Replace old audio conversion info or add new\n",
        "        if 'AUDIO_CONVERSION' in existing_context:\n",
        "            # Replace existing audio conversion info\n",
        "            context_parts = existing_context.split(' | ')\n",
        "            new_parts = [part for part in context_parts if not part.startswith('AUDIO_CONVERSION')]\n",
        "            new_parts.append(processing_summary)\n",
        "            df.at[idx, 'Context'] = ' | '.join(new_parts)\n",
        "        else:\n",
        "            # Add new processing info\n",
        "            df.at[idx, 'Context'] = (existing_context + ' | ' if existing_context else '') + processing_summary\n",
        "\n",
        "# Add metadata columns for tracking\n",
        "df['audio_processing_timestamp'] = current_timestamp\n",
        "df['audio_files_valid'] = (df['First Audio Clip'].apply(has_valid_audio) & \n",
        "                          df['Last Audio Clip'].apply(has_valid_audio))\n",
        "\n",
        "# Save both progress and final versions\n",
        "for save_path, description in [(PROGRESS_CSV, \"progress checkpoint\"), (FINAL_CSV, \"final dataset\")]:\n",
        "    try:\n",
        "        df.to_csv(save_path, index=False)\n",
        "        file_size = save_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"✅ Saved {description}: {save_path.name} ({file_size:.2f} MB)\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to save {description}: {e}\")\n",
        "\n",
        "print(f\"📊 Final dataset statistics:\")\n",
        "print(f\"   Rows: {len(df)} (filtered from {original_row_count})\")\n",
        "print(f\"   Columns: {len(df.columns)}\")\n",
        "print(f\"   Audio coverage: {coverage_stats['rows_with_both_audio']}/{len(df)} complete pairs\")\n",
        "\n",
        "# Show enhanced sample of final data\n",
        "audio_rows = df[df['audio_files_valid'] == True]\n",
        "if len(audio_rows) > 0:\n",
        "    print(f\"\\n📋 Sample rows with complete audio pairs ({len(audio_rows)} total):\")\n",
        "    for i, (idx, row) in enumerate(audio_rows.head(3).iterrows()):\n",
        "        identifier = row.get('School_Clip', f'row_{idx}')\n",
        "        first_audio = row['First Audio Clip']\n",
        "        last_audio = row['Last Audio Clip']\n",
        "\n",
        "        print(f\"   Row {idx} ({identifier}):\")\n",
        "        print(f\"      First audio: ✅ {Path(first_audio).name if first_audio else 'None'}\")\n",
        "        print(f\"      Last audio:  ✅ {Path(last_audio).name if last_audio else 'None'}\")\n",
        "\n",
        "# Save processing metadata as JSON for reference\n",
        "metadata_file = AUDIO_OUTPUT_DIR / 'processing_metadata.json'\n",
        "try:\n",
        "    with open(metadata_file, 'w') as f:\n",
        "        json.dump(processing_metadata, f, indent=2)\n",
        "    print(f\"📄 Saved processing metadata: {metadata_file.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️  Could not save metadata: {e}\")\n",
        "\n",
        "# Enhanced cleanup with statistics\n",
        "print(f\"\\n🧹 Enhanced cleanup of temporary files...\")\n",
        "cleanup_stats = {'files_cleaned': 0, 'space_freed_mb': 0}\n",
        "\n",
        "try:\n",
        "    for temp_file in TEMP_DIR.glob('*'):\n",
        "        try:\n",
        "            file_size = temp_file.stat().st_size\n",
        "            temp_file.unlink()\n",
        "            cleanup_stats['files_cleaned'] += 1\n",
        "            cleanup_stats['space_freed_mb'] += file_size / (1024 * 1024)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if TEMP_DIR.exists() and not any(TEMP_DIR.iterdir()):\n",
        "        TEMP_DIR.rmdir()\n",
        "\n",
        "    print(f\"   Cleaned {cleanup_stats['files_cleaned']} files, freed {cleanup_stats['space_freed_mb']:.1f} MB\")\n",
        "except Exception as e:\n",
        "    print(f\"   Warning: Partial cleanup failure: {e}\")\n",
        "\n",
        "print(\"✅ Enhanced dataset saving and cleanup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc24966",
      "metadata": {
        "id": "adc24966"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------\n",
        "# Comprehensive Final Report with Enhanced Analytics\n",
        "# -----------------------------------------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🎉 ENHANCED AUDIO CONVERSION PIPELINE COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Calculate comprehensive processing metrics\n",
        "if 'start_time' in locals():\n",
        "    total_processing_time = time.time() - start_time\n",
        "    processing_occurred = True\n",
        "else:\n",
        "    total_processing_time = 0\n",
        "    processing_occurred = False\n",
        "\n",
        "# Enhanced system resource tracking\n",
        "final_resources = get_system_resources()\n",
        "resource_usage = {\n",
        "    'memory_used_gb': max(0, resources['memory_available_gb'] - final_resources['memory_available_gb']),\n",
        "    'disk_used_gb': max(0, resources['disk_free_gb'] - final_resources['disk_free_gb']),\n",
        "    'memory_efficiency': (resources['memory_available_gb'] - final_resources['memory_available_gb']) / resources['memory_total_gb'] * 100\n",
        "}\n",
        "\n",
        "print(f\"📊 COMPREHENSIVE PROCESSING SUMMARY:\")\n",
        "print(f\"   Original dataset: {original_row_count} rows\")\n",
        "print(f\"   Filtered dataset: {len(df)} rows (kept {len(df)/original_row_count*100:.1f}%)\")\n",
        "print(f\"   Video clips to process: {len(clips_to_process) if 'clips_to_process' in locals() else 0}\")\n",
        "print(f\"   Successful conversions: {len([r for r in results if r['success']]) if 'results' in locals() and processing_occurred else 'N/A'}\")\n",
        "print(f\"   Valid audio files: {validation_stats['valid_files']}\")\n",
        "print(f\"   Complete audio pairs: {coverage_stats['rows_with_both_audio']}\")\n",
        "print(f\"   Total audio collection: {validation_stats['total_size_mb']:.1f} MB\")\n",
        "\n",
        "print(f\"\\n⚡ ENHANCED PERFORMANCE METRICS:\")\n",
        "if processing_occurred and total_processing_time > 0:\n",
        "    print(f\"   Total processing time: {total_processing_time/60:.1f} minutes\")\n",
        "    if 'clips_to_process' in locals() and len(clips_to_process) > 0:\n",
        "        print(f\"   Average time per clip: {total_processing_time/len(clips_to_process):.1f} seconds\")\n",
        "        print(f\"   Processing throughput: {len(clips_to_process)/total_processing_time:.2f} clips/second\")\n",
        "    \n",
        "    if 'processor' in locals():\n",
        "        final_stats = processor.get_enhanced_stats()\n",
        "        print(f\"   GPU acceleration used: {final_stats['gpu_usage_percent']:.1f}% of successful conversions\")\n",
        "        print(f\"   GPU vs CPU breakdown: {final_stats['gpu_successful']} GPU, {final_stats['cpu_fallback']} CPU\")\n",
        "else:\n",
        "    print(f\"   No processing needed - all clips already converted\")\n",
        "\n",
        "print(f\"\\n🖥️  RESOURCE UTILIZATION:\")\n",
        "print(f\"   Workers deployed: {MAX_WORKERS} total, {GPU_MAX_CONCURRENT} GPU slots\")\n",
        "print(f\"   Hardware acceleration: {GPU_INFO['acceleration_flag'] if GPU_INFO['available'] else 'CPU-only processing'}\")\n",
        "print(f\"   Memory utilization: {resource_usage['memory_efficiency']:.1f}% of total RAM\")\n",
        "print(f\"   Peak memory usage: {resource_usage['memory_used_gb']:.2f} GB\")\n",
        "print(f\"   Disk space consumed: {resource_usage['disk_used_gb']:.2f} GB\")\n",
        "\n",
        "print(f\"\\n📁 OUTPUT FILES AND LOCATIONS:\")\n",
        "print(f\"   Final dataset: {FINAL_CSV}\")\n",
        "print(f\"   Progress backup: {PROGRESS_CSV}\")\n",
        "print(f\"   Audio files directory: {AUDIO_OUTPUT_DIR}\")\n",
        "print(f\"   Audio files created: {len(list(AUDIO_OUTPUT_DIR.glob('*.mp3')))}\")\n",
        "print(f\"   Processing metadata: {AUDIO_OUTPUT_DIR / 'processing_metadata.json'}\")\n",
        "\n",
        "print(f\"\\n📈 QUALITY AND COVERAGE ANALYSIS:\")\n",
        "total_possible_audio = len(df) * 2  # Two audio clips per row\n",
        "actual_audio_files = validation_stats['valid_files']\n",
        "conversion_success_rate = (actual_audio_files / total_possible_audio) * 100 if total_possible_audio > 0 else 0\n",
        "\n",
        "print(f\"   Overall conversion success: {conversion_success_rate:.1f}% ({actual_audio_files}/{total_possible_audio})\")\n",
        "print(f\"   Complete pairs coverage: {coverage_stats['rows_with_both_audio']}/{len(df)} ({coverage_stats['rows_with_both_audio']/len(df)*100:.1f}%)\")\n",
        "print(f\"   Partial coverage: {coverage_stats['rows_with_any_audio'] - coverage_stats['rows_with_both_audio']} rows\")\n",
        "print(f\"   Data quality: {validation_stats['valid_files']} valid, {validation_stats['missing_files'] + validation_stats['empty_files'] + validation_stats['corrupted_files']} invalid\")\n",
        "print(f\"   Size distribution: {size_stats['min']:.2f}-{size_stats['max']:.2f} MB (avg: {size_stats['mean']:.2f} MB)\")\n",
        "\n",
        "print(f\"\\n🎯 OPTIMIZATION ACHIEVEMENTS:\")\n",
        "optimizations = [\n",
        "    \"✅ Intelligent GPU memory management with fallback\",\n",
        "    \"✅ Progressive data persistence (no work lost)\",\n",
        "    \"✅ Resume capability for interrupted sessions\",\n",
        "    \"✅ Robust data filtering (both video clips required)\",\n",
        "    \"✅ Enhanced concurrent processing with resource awareness\",\n",
        "    \"✅ Comprehensive error handling and retry logic\",\n",
        "    \"✅ Real-time resource monitoring and adjustment\",\n",
        "    \"✅ Quality validation with integrity checking\",\n",
        "    \"✅ Efficient streaming downloads (minimal disk usage)\",\n",
        "    \"✅ Automatic cleanup and space management\"\n",
        "]\n",
        "\n",
        "for opt in optimizations:\n",
        "    print(f\"   {opt}\")\n",
        "\n",
        "print(f\"\\n🚀 NEXT STEPS AND RECOMMENDATIONS:\")\n",
        "print(f\"   1. Use the validated audio files for transcription processing\")\n",
        "print(f\"   2. Run speech-to-text analysis on the {validation_stats['valid_files']} MP3 files\")\n",
        "print(f\"   3. The dataset contains complete paths to all audio clips\")\n",
        "print(f\"   4. All files are safely stored in Google Drive with backup\")\n",
        "print(f\"   5. Progress data allows resuming if needed for additional clips\")\n",
        "\n",
        "if validation_stats['missing_files'] > 0 or validation_stats['empty_files'] > 0 or validation_stats['corrupted_files'] > 0:",
        "    print(f\"   6. Address missing, empty, or corrupted files before proceeding\")\n",
        "else:",
        "    print(f\"   6. No integrity issues detected - proceed with transcription\")\n",
        "\n",
        "print(f\"\n✅ AUDIO CONVERSION PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c3cb9e4a9e3483f96194e51aa5d0121": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4709c80dd65c4e72affcf6c692b17fee",
            "placeholder": "​",
            "style": "IPY_MODEL_d39b61ec11a6487ab403324a74ddde27",
            "value": "Converting videos to audio:  28%"
          }
        },
        "11148a25b168400990f11ca57f533876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c4419f743914cba92cbbf165108937f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "428148746f514c87905d494d7247687a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c3cb9e4a9e3483f96194e51aa5d0121",
              "IPY_MODEL_8ea4d3b23be4483880a78c11a7386425",
              "IPY_MODEL_c35dd6cde24b4be293cdfa3df07568af"
            ],
            "layout": "IPY_MODEL_3c4419f743914cba92cbbf165108937f"
          }
        },
        "4709c80dd65c4e72affcf6c692b17fee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "483c95b97af34461bf569df621f3d18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ea4d3b23be4483880a78c11a7386425": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8619af1bdd47a3b658fac07d29d99f",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_483c95b97af34461bf569df621f3d18b",
            "value": 200
          }
        },
        "9635bc3c4e4c4235a1816aeea704d294": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35dd6cde24b4be293cdfa3df07568af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9635bc3c4e4c4235a1816aeea704d294",
            "placeholder": "​",
            "style": "IPY_MODEL_11148a25b168400990f11ca57f533876",
            "value": " 200/726 [1:21:31&lt;5:25:23, 37.12s/clip, Success=182/200, Current=447268 Clip 2_first]"
          }
        },
        "d39b61ec11a6487ab403324a74ddde27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc8619af1bdd47a3b658fac07d29d99f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
